{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43c1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianajimenez/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras_hub\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow as tf\n",
    "from tensorflow_text.tools.wordpiece_vocab import (\n",
    "    bert_vocab_from_dataset,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df1779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for pre-parsing\n",
    "from pyparsing import Word, alphas as pp_alpha, nums as pp_nums\n",
    "import pyparsing as pp\n",
    "pp.ParserElement.enablePackrat()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex rules\n",
    "\n",
    "alpha_regexp  = r\"(?!((?:THUMB-)?(?:IX|POSS|SELF)))[A-Z](?:[A-Z/_'-]*[A-Z])?(?:\\.)?\"\n",
    "lookahead_regexp = r\"(?:(?![a-z])|(?=wg))\"\n",
    "\n",
    "word_all_regexp = r\"\"\"(?x)\n",
    "    (?: %s )\n",
    "    %s\n",
    "\"\"\" % (alpha_regexp, lookahead_regexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbd4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conventions kept for parsing\n",
    "\n",
    "cl_prefix = pp.one_of([\"CL\", \"DCL\", \"LCL\", \"SCL\", \"BCL\", \"BPCL\", \"PCL\", \"ICL\"])\n",
    "fs_prefix = pp.Literal(\"fs-\")\n",
    "index_core_ix = pp.Literal(\"IX\")\n",
    "other_index_core = pp.one_of([\"POSS\", \"SELF\"])\n",
    "compound = pp.Literal(\"+\")\n",
    "hashtag = pp.Literal(\"#\")\n",
    "sym = pp.Literal(\">\")\n",
    "par1 = pp.Literal(\"(\")\n",
    "par2 = pp.Literal(\")\")\n",
    "dash = pp.Literal(\"-\")\n",
    "contraction = pp.Literal(\"^\")\n",
    "colon = pp.Literal(\":\")\n",
    "omit_quote = pp.Literal(\"xx\")\n",
    "period = pp.Literal(\".\")\n",
    "alpha = pp.Word(pp_alpha, max=1)\n",
    "num = pp.Word(pp_nums, max=1)\n",
    "word = pp.Regex(word_all_regexp, flags=re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar rules\n",
    "\n",
    "full_grammar = pp.OneOrMore(\n",
    "    cl_prefix |               # classifiers like CL, DCL, etc.\n",
    "    fs_prefix |               # fingerspelling fs\n",
    "    index_core_ix |           # IX\n",
    "    other_index_core |        # POSS, SELF\n",
    "    word |\n",
    "    compound |                # +\n",
    "    hashtag |                 # #\n",
    "    sym |                     # >\n",
    "    contraction |             # ^\n",
    "    colon |                   # :\n",
    "    par1 | par2 |             # ( and )\n",
    "    omit_quote |              # xx\n",
    "    period |                  # .\n",
    "    dash |\n",
    "    num |\n",
    "    alpha                     # fallback LAST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45096aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCL', ':', '1', 'xx']\n",
      "['IX', '-', '1', 'p', 'BCL', 'xx', 'FIND/FIND-OUT', 'fs-', 'HER']\n"
     ]
    }
   ],
   "source": [
    "# testing grammar parsing\n",
    "\n",
    "trial = full_grammar.parse_string(\"SCL:1xx\", parse_all=True).asList()\n",
    "trial2 = full_grammar.parse_string(\"IX-1p BCLxx FIND/FIND-OUT fs-HER\", parse_all=True).asList()\n",
    "\n",
    "print(trial)\n",
    "print(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258c52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize based on predefined grammar rules\n",
    "\n",
    "def custom_asl_tokenize(text):\n",
    "    try:\n",
    "        return full_grammar.parse_string(text, parse_all=True).asList()\n",
    "    except pp.ParseException as pe:\n",
    "        print(f\"Failed to parse: {pe}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d3e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eng_tokenize(text):\n",
    "    # Perserve punctuation and digits\n",
    "    text = re.sub(r'([^\\w\\s]|\\d)', r' \\1 ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split on whitespace\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc0cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCL', ':', '1', 'xx']\n",
      "['SCL', ':', '1', 'xx', 'SHOWER', 'WASH', 'FEEL', 'THUMBS-UP/GOOD']\n"
     ]
    }
   ],
   "source": [
    "# testing custom_asl_tokenize\n",
    "\n",
    "trial = custom_asl_tokenize(\"SCL:1xx\")\n",
    "trial2 = custom_asl_tokenize('SCL:1xx SHOWER WASH FEEL THUMBS-UP/GOOD')\n",
    "\n",
    "print(trial)\n",
    "print(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae869df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['but', 'all', 'the', 'same', ',', 'he', 'told', 'me', 'i', 'better', 'go', 'downstairs', 'and', 'get', 'an', 'x', '-', 'ray', '.']\n",
      "['i', 'waited', '2', '3', '4', 'years', 'and', '2', ',', '1', '4', '2', 'days']\n"
     ]
    }
   ],
   "source": [
    "# testing custom_eng_tokenize\n",
    "\n",
    "trial = custom_eng_tokenize(\"But all the same, he told me I better go downstairs and get an x-ray.\")\n",
    "trial2 = custom_eng_tokenize('I waited 234 years and 2,142 days')\n",
    "\n",
    "print(trial)\n",
    "print(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79a6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters / hyperparameters\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 512\n",
    "NUM_HEADS = 4\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "ENG_VOCAB_SIZE = 3092 + 4\n",
    "ASL_VOCAB_SIZE = 1810 + 4\n",
    "num_samples = 3380\n",
    "\n",
    "data_path = \"/Users/adrianajimenez/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/sent_pairs_joined.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c737cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_cl(text):\n",
    "    cl_pre = (\"CL\", \"DCL\", \"LCL\", \"SCL\", \"BCL\", \"BPCL\", \"PCL\", \"ICL\")\n",
    "    if text.startswith(cl_pre) and \":\" in text:\n",
    "        index = text.index(\":\")\n",
    "        text = text[:index]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df98b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 47), (line:1, col:48)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 83), (line:1, col:84)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 72), (line:1, col:73)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 47), (line:1, col:48)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 119), (line:1, col:120)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 134), (line:1, col:135)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 46), (line:1, col:47)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 189), (line:1, col:190)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 86), (line:1, col:87)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 145), (line:1, col:146)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 49), (line:1, col:50)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 49), (line:1, col:50)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 110), (line:1, col:111)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 101), (line:1, col:102)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 42), (line:1, col:43)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 74), (line:1, col:75)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 63), (line:1, col:64)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 67), (line:1, col:68)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 89), (line:1, col:90)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 94), (line:1, col:95)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 300), (line:1, col:301)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 65), (line:1, col:66)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 35), (line:1, col:36)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 155), (line:1, col:156)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 105), (line:1, col:106)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 187), (line:1, col:188)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 44), (line:1, col:45)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 69), (line:1, col:70)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 94), (line:1, col:95)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 40), (line:1, col:41)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 79), (line:1, col:80)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 63), (line:1, col:64)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 13), (line:1, col:14)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 12), (line:1, col:13)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 13), (line:1, col:14)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 49), (line:1, col:50)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 175), (line:1, col:176)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 176), (line:1, col:177)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 113), (line:1, col:114)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 43), (line:1, col:44)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 125), (line:1, col:126)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 29), (line:1, col:30)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 100), (line:1, col:101)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 94), (line:1, col:95)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 73), (line:1, col:74)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 130), (line:1, col:131)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 26), (line:1, col:27)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 70), (line:1, col:71)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 13), (line:1, col:14)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 35), (line:1, col:36)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 29), (line:1, col:30)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 30), (line:1, col:31)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 6), (line:1, col:7)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 25), (line:1, col:26)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 6), (line:1, col:7)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 44), (line:1, col:45)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 29), (line:1, col:30)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 48), (line:1, col:49)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 30), (line:1, col:31)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 55), (line:1, col:56)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 51), (line:1, col:52)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 53), (line:1, col:54)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 41), (line:1, col:42)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 97), (line:1, col:98)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 41), (line:1, col:42)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 12), (line:1, col:13)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 107), (line:1, col:108)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 65), (line:1, col:66)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 71), (line:1, col:72)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 13), (line:1, col:14)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 48), (line:1, col:49)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 47), (line:1, col:48)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 40), (line:1, col:41)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 60), (line:1, col:61)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 31), (line:1, col:32)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 69), (line:1, col:70)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 26), (line:1, col:27)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 52), (line:1, col:53)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 73), (line:1, col:74)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 48), (line:1, col:49)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 68), (line:1, col:69)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 59), (line:1, col:60)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 30), (line:1, col:31)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 43), (line:1, col:44)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 31), (line:1, col:32)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 68), (line:1, col:69)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 44), (line:1, col:45)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 48), (line:1, col:49)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 51), (line:1, col:52)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 53), (line:1, col:54)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 84), (line:1, col:85)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 58), (line:1, col:59)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 43), (line:1, col:44)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 106), (line:1, col:107)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 78), (line:1, col:79)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 33), (line:1, col:34)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 63), (line:1, col:64)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 43), (line:1, col:44)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 102), (line:1, col:103)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 31), (line:1, col:32)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 29), (line:1, col:30)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 52), (line:1, col:53)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 40), (line:1, col:41)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 39), (line:1, col:40)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 73), (line:1, col:74)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 84), (line:1, col:85)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 52), (line:1, col:53)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 57), (line:1, col:58)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 41), (line:1, col:42)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 51), (line:1, col:52)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 51), (line:1, col:52)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 90), (line:1, col:91)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 98), (line:1, col:99)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 68), (line:1, col:69)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 63), (line:1, col:64)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 52), (line:1, col:53)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 31), (line:1, col:32)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 44), (line:1, col:45)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 56), (line:1, col:57)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 30), (line:1, col:31)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 38), (line:1, col:39)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 55), (line:1, col:56)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 60), (line:1, col:61)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 46), (line:1, col:47)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 63), (line:1, col:64)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 60), (line:1, col:61)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 33), (line:1, col:34)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 33), (line:1, col:34)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 72), (line:1, col:73)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 28), (line:1, col:29)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 33), (line:1, col:34)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 58), (line:1, col:59)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 60), (line:1, col:61)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 54), (line:1, col:55)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 36), (line:1, col:37)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 57), (line:1, col:58)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 33), (line:1, col:34)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 24), (line:1, col:25)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 30), (line:1, col:31)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 35), (line:1, col:36)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 14), (line:1, col:15)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 20), (line:1, col:21)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 46), (line:1, col:47)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 12), (line:1, col:13)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 16), (line:1, col:17)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 17), (line:1, col:18)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 6), (line:1, col:7)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 34), (line:1, col:35)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 4), (line:1, col:5)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 7), (line:1, col:8)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 23), (line:1, col:24)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 21), (line:1, col:22)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 22), (line:1, col:23)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 45), (line:1, col:46)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 6), (line:1, col:7)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 3), (line:1, col:4)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 15), (line:1, col:16)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 37), (line:1, col:38)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 42), (line:1, col:43)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 19), (line:1, col:20)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 10), (line:1, col:11)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 9), (line:1, col:10)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 90), (line:1, col:91)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 11), (line:1, col:12)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 47), (line:1, col:48)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 69), (line:1, col:70)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 27), (line:1, col:28)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 50), (line:1, col:51)\n",
      "Failed to parse: Expected end of text, found '/'  (at char 5), (line:1, col:6)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 18), (line:1, col:19)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 8), (line:1, col:9)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 41), (line:1, col:42)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 25), (line:1, col:26)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 48), (line:1, col:49)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 99), (line:1, col:100)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 32), (line:1, col:33)\n",
      "Failed to parse: Expected end of text, found '_'  (at char 75), (line:1, col:76)\n",
      "eng_tokens: ['!', '\"', '$', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '`', 'a', 'aaa', 'aaahhh', 'abcs', 'abdominal', 'able', 'about', 'above', 'abuse', 'accept', 'acceptable', 'acceptance', 'accepted', 'accident', 'accidentally', 'accommodations', 'accomplishment', 'across', 'act', 'acting', 'action', 'actions', 'activities', 'actor', 'actors', 'actually', 'added', 'addicted', 'addicts', 'admit', 'adopt', 'adopted', 'adopts', 'advantage', 'adventure', 'advice', 'advisior', 'ae', 'afford', 'afraid', 'after', 'afternoon', 'again', 'against', 'age', 'ago', 'agree', 'agreed', 'ah', 'ahead', 'ahh', 'ail', 'air', 'airline', 'airlines', 'airplanes', 'alarm', 'alcohol', 'alec', 'ali', 'alike', 'alive', 'all', 'allergic', 'allow', 'allowed', 'almost', 'alone', 'along', 'alphabetical', 'already', 'alright', 'also', 'always', 'am', 'amazing', 'american', 'amy', 'an', 'analyze', 'analyzed', 'analyzing', 'ancestors', 'and', 'angela', 'angeles', 'anger', 'angled', 'angry', 'animal', 'animals', 'ankle', 'ann', 'anniversary', 'annotation', 'announced', 'annoying', 'annual', 'another', 'answer', 'answers', 'any', 'anybody', 'anymore', 'anyone', 'anything', 'anyway', 'anywhere', 'apartment', 'applaud', 'apple', 'apples', 'applied', 'apply', 'appointment', 'appreciated', 'approach', 'approached', 'approches', 'appropriate', 'appropriately', 'are', 'area', 'areas', 'aren', 'arm', 'arms', 'around', 'arrest', 'arrested', 'arried', 'arrive', 'arrived', 'arrives', 'arriving', 'article', 'as', 'asia', 'asian', 'aside', 'ask', 'asked', 'asking', 'asks', 'asl', 'asleep', 'aspect', 'assaulted', 'assess', 'assigned', 'assistant', 'associated', 'associating', 'assorted', 'assume', 'assumed', 'assumption', 'astonished', 'at', 'ate', 'attack', 'attacker', 'attempt', 'attending', 'attention', 'audio', 'audiologist', 'audiovocal', 'audition', 'aunt', 'australia', 'automatic', 'automatically', 'average', 'avoid', 'awake', 'award', 'aware', 'away', 'awe', 'awful', 'awfully', 'awkward', 'b', 'babies', 'baby', 'back', 'background', 'bad', 'bag', 'bagel', 'bags', 'bake', 'balance', 'bald', 'baldwin', 'ball', 'band', 'bandage', 'banged', 'banging', 'banks', 'bar', 'barack', 'barbaric', 'barbeque', 'barely', 'baritone', 'baseball', 'based', 'basically', 'basketball', 'bathroom', 'bauhman', 'bauman', 'bawls', 'bbq', 'be', 'beach', 'beacuse', 'bear', 'beat', 'beating', 'beats', 'beautiful', 'became', 'because', 'become', 'becomes', 'becoming', 'bed', 'been', 'beer', 'before', 'began', 'begin', 'beginning', 'behaving', 'behind', 'being', 'believe', 'belong', 'below', 'belt', 'ben', 'benard', 'beneath', 'bent', 'berry', 'best', 'beth', 'better', 'between', 'beverly', 'beyond', 'bib', 'bible', 'bicycle', 'big', 'bigger', 'bike', 'bill', 'birth', 'birthday', 'bit', 'bite', 'black', 'bladder', 'blamed', 'blames', 'bled', 'bleed', 'bleeding', 'blew', 'block', 'blocks', 'blood', 'bloomberg', 'blow', 'blown', 'blue', 'blueberry', 'boat', 'bob', 'body', 'boldly', 'bonfire', 'bonfires', 'book', 'books', 'boots', 'border', 'bored', 'boring', 'born', 'borrow', 'borrowed', 'boss', 'boston', 'bostonians', 'both', 'bother', 'bothered', 'bottle', 'bought', 'bowl', 'box', 'boxer', 'boxes', 'boxing', 'boy', 'boys', 'braced', 'bracelet', 'bragg', 'brakes', 'bread', 'break', 'breakdown', 'breakfast', 'breaking', 'breaks', 'breath', 'breathe', 'breathing', 'brick', 'bricks', 'bride', 'bring', 'brings', 'broccoli', 'broke', 'broken', 'brookline', 'brother', 'brothers', 'brought', 'brownish', 'bruce', 'bruise', 'bu', 'bubbles', 'bucket', 'bucks', 'build', 'building', 'buildings', 'built', 'bumps', 'bun', 'bunch', 'bundled', 'burger', 'burn', 'burned', 'burp', 'bus', 'bush', 'business', 'but', 'butcher', 'butter', 'butts', 'buy', 'buying', 'buys', 'by', 'c', 'cabin', 'cabinet', 'cabinets', 'cafeteria', 'cake', 'cakes', 'calfornia', 'california', 'call', 'called', 'calling', 'calls', 'calm', 'calmly', 'came', 'camp', 'campground', 'camping', 'can', 'cancel', 'canceled', 'cancelled', 'cancer', 'candidate', 'candy', 'cannot', 'capable', 'cape', 'car', 'card', 'care', 'career', 'careful', 'carol', 'carried', 'carrying', 'cars', 'case', 'cases', 'casino', 'cat', 'catch', 'categories', 'categorizations', 'category', 'caucus', 'caught', 'cause', 'caused', 'caviar', 'cds', 'celebrate', 'celebrated', 'celebrating', 'celebrations', 'cereal', 'chair', 'chairs', 'chalkboard', 'challenge', 'challenging', 'chance', 'change', 'changed', 'changing', 'channel', 'chapter', 'character', 'characteristics', 'charge', 'charles', 'chased', 'chasing', 'chat', 'chatted', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'check', 'checked', 'checklist', 'checks', 'cheer', 'cheered', 'cheering', 'cheese', 'chemicals', 'chess', 'chicago', 'chicken', 'child', 'children', 'chimney', 'china', 'chocolate', 'choice', 'choices', 'chokes', 'choose', 'chopped', 'christmas', 'chrome', 'church', 'churning', 'cigarette', 'cigarettes', 'cities', 'city', 'clanking', 'class', 'classroom', 'clean', 'cleaned', 'cleaning', 'cleans', 'clear', 'clearly', 'climb', 'climbing', 'clip', 'cliques', 'clock', 'clooney', 'close', 'closed', 'closer', 'closes', 'closing', 'clothes', 'club', 'clubs', 'clue', 'cnn', 'coach', 'coat', 'coats', 'cochlear', 'cod', 'coda', 'codas', 'code', 'coffee', 'cofffee', 'coffin', 'cognitive', 'cohesiveness', 'cold', 'colder', 'collaborate', 'collar', 'collars', 'colleague', 'colleagues', 'collect', 'collected', 'college', 'collided', 'color', 'colorado', 'colors', 'come', 'comedy', 'comes', 'comfortable', 'coming', 'commendable', 'comment', 'comments', 'communicate', 'communicated', 'communication', 'community', 'commute', 'commutes', 'commuting', 'company', 'compare', 'compared', 'compares', 'comparison', 'compatible', 'compelled', 'competition', 'complete', 'completed', 'completely', 'completing', 'comprehensible', 'computer', 'computers', 'concept', 'conception', 'concert', 'conditioning', 'conduct', 'confidence', 'confident', 'conflict', 'confusion', 'connected', 'connection', 'conntected', 'considered', 'considering', 'constantly', 'contact', 'contemptible', 'context', 'continue', 'continued', 'continues', 'contributed', 'contro', 'control', 'controlled', 'controlling', 'conversation', 'cooked', 'cookies', 'cooking', 'cool', 'cooler', 'coordinator', 'cop', 'copies', 'cops', 'copy', 'corn', 'corner', 'correlated', 'costs', 'costume', 'cough', 'coughing', 'coughs', 'could', 'couldn', 'counselor', 'countries', 'country', 'couple', 'course', 'cousin', 'cover', 'covers', 'cow', 'cows', 'cpr', 'cracked', 'crash', 'crashed', 'crashes', 'crashing', 'crazy', 'cream', 'create', 'creative', 'creatively', 'creepy', 'crib', 'cried', 'crisis', 'criteria', 'criticize', 'crops', 'cross', 'crossing', 'crowd', 'crowded', 'cruiser', 'crying', 'csun', 'cued', 'cuff', 'cultrual', 'cultural', 'culturally', 'culture', 'cultures', 'cup', 'cups', 'curious', 'current', 'currently', 'curvy', 'cut', 'cute', 'cutting', 'd', 'dad', 'dairy', 'daisy', 'dana', 'dance', 'danced', 'dark', 'date', 'daughter', 'dawn', 'day', 'days', 'dead', 'deaf', 'deafies', 'deal', 'dean', 'dear', 'deathly', 'december', 'decide', 'decided', 'decides', 'decision', 'decorate', 'decrease', 'deep', 'deeply', 'deer', 'definitely', 'degrees', 'delicious', 'delighted', 'demi', 'democrat', 'depend', 'depends', 'depressed', 'depth', 'described', 'desire', 'dessert', 'destroy', 'destroyed', 'determine', 'develop', 'developed', 'development', 'developments', 'devices', 'diagnoses', 'diagnosis', 'dialogue', 'did', 'didn', 'didnt', 'died', 'diego', 'difference', 'differences', 'different', 'differently', 'difficult', 'difficulty', 'dimwitted', 'dinner', 'direct', 'direction', 'directions', 'disappointed', 'disciplinary', 'disconnected', 'discuss', 'discussed', 'discussing', 'discussion', 'disease', 'disgusted', 'dislike', 'disorder', 'disordered', 'disorders', 'displayed', 'disruption', 'dissipate', 'distance', 'disturbed', 'diversity', 'do', 'doctor', 'doctors', 'does', 'doesn', 'dog', 'doing', 'dollar', 'dollars', 'dominance', 'don', 'donalds', 'done', 'donna', 'donut', 'door', 'doorbell', 'doorknob', 'doors', 'dorm', 'dorms', 'double', 'doubt', 'down', 'downhill', 'downstairs', 'drag', 'drain', 'dramas', 'drank', 'dream', 'dreams', 'dress', 'drink', 'drinking', 'drinks', 'drive', 'driver', 'drivers', 'drives', 'driving', 'drop', 'dropped', 'dropping', 'drops', 'drove', 'drown', 'drug', 'drugs', 'drunk', 'dry', 'due', 'dug', 'dumbfounded', 'dumped', 'during', 'dvd', 'dye', 'dyed', 'dying', 'each', 'ear', 'earlier', 'early', 'ears', 'easier', 'easily', 'easy', 'eat', 'eaten', 'eating', 'eats', 'economic', 'economy', 'edge', 'education', 'effort', 'eight', 'either', 'elbow', 'elected', 'election', 'elementary', 'eleven', 'eliminate', 'elite', 'else', 'email', 'embarrassed', 'embarrassing', 'embraces', 'emergency', 'emit', 'emits', 'emitting', 'emotion', 'empty', 'enable', 'encounter', 'encouraging', 'end', 'ended', 'ends', 'enemy', 'engine', 'english', 'engrossed', 'enjoy', 'enjoyed', 'enjoying', 'enjoys', 'ennis', 'enough', 'enrolled', 'enter', 'entered', 'entering', 'enters', 'envelope', 'environment', 'environments', 'equal', 'equally', 'erick', 'escape', 'escapes', 'especially', 'establishing', 'estimation', 'etc', 'europe', 'even', 'event', 'eventually', 'ever', 'everwhere', 'every', 'everyday', 'everyone', 'everything', 'everytime', 'exactly', 'exam', 'example', 'exceed', 'except', 'excess', 'excessive', 'exchange', 'exchanged', 'exchanging', 'excited', 'excused', 'exercise', 'exhausted', 'exist', 'exit', 'expanded', 'expectation', 'expectations', 'expected', 'expecting', 'expects', 'expenses', 'expensive', 'experience', 'experienced', 'experiences', 'experiment', 'expert', 'explain', 'explained', 'explaining', 'express', 'expression', 'extra', 'extremely', 'eye', 'eyes', 'f', 'face', 'facial', 'facing', 'fact', 'fail', 'fall', 'falls', 'family', 'famous', 'fan', 'fancy', 'fans', 'far', 'farm', 'farmland', 'fart', 'farther', 'fascinated', 'fast', 'father', 'fault', 'favorite', 'federation', 'fedex', 'feed', 'feeding', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'fenced', 'few', 'field', 'fifteen', 'fight', 'fighting', 'figure', 'filled', 'films', 'final', 'finally', 'find', 'finds', 'fine', 'fined', 'finger', 'fingernails', 'fingers', 'finish', 'finished', 'finishes', 'finishing', 'fire', 'fired', 'fireplace', 'fires', 'firewood', 'fireworks', 'first', 'fish', 'fishing', 'fist', 'fists', 'fit', 'five', 'fix', 'fixed', 'flash', 'flashed', 'flat', 'flavorful', 'flew', 'flies', 'flight', 'flip', 'flood', 'flooding', 'floor', 'flops', 'florida', 'flowers', 'fluent', 'flushed', 'fly', 'flying', 'focus', 'focused', 'focusing', 'follow', 'following', 'food', 'foot', 'football', 'for', 'forbidden', 'forest', 'forever', 'forget', 'forgot', 'forks', 'form', 'formal', 'former', 'forth', 'forward', 'found', 'four', 'fourth', 'france', 'francisco', 'frank', 'fraternity', 'freak', 'free', 'french', 'frends', 'frequently', 'fresh', 'fresher', 'freshman', 'friday', 'friend', 'friendly', 'friends', 'fries', 'frisbee', 'from', 'front', 'frozen', 'fruit', 'fruits', 'frustrated', 'fuck', 'fucked', 'full', 'fumble', 'fun', 'funny', 'further', 'future', 'gain', 'gaining', 'gallaudet', 'gamble', 'gambled', 'gambling', 'game', 'games', 'garage', 'gas', 'gate', 'gather', 'gave', 'gazpacho', 'geez', 'gender', 'general', 'generally', 'generations', 'genius', 'gently', 'george', 'germany', 'gesture', 'gestured', 'gestures', 'get', 'gets', 'getting', 'ghosts', 'gift', 'gilbert', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'glass', 'glasses', 'glitter', 'globe', 'go', 'gobble', 'god', 'goes', 'going', 'gold', 'golf', 'gone', 'good', 'google', 'goose', 'got', 'gotten', 'grabbed', 'graduate', 'graduated', 'grandfather', 'grandma', 'grandstand', 'grants', 'grass', 'great', 'greatechwaech', 'greater', 'green', 'grew', 'grief', 'grin', 'grocery', 'groom', 'gross', 'ground', 'group', 'grouped', 'groups', 'grow', 'growing', 'growth', 'grun', 'grunt', 'gruntal', 'grunting', 'grunts', 'guarantee', 'guaranteed', 'guess', 'guest', 'guidelines', 'gulped', 'guy', 'guys', 'gym', 'habits', 'had', 'hadn', 'hah', 'haha', 'hair', 'half', 'hall', 'hallway', 'hamburger', 'hamburgers', 'hand', 'handcuffed', 'handcuffs', 'handle', 'hands', 'hang', 'hanging', 'hangups', 'happen', 'happened', 'happening', 'happens', 'happily', 'happiness', 'happy', 'hard', 'harry', 'harsh', 'has', 'hasn', 'hastily', 'hate', 'hates', 'haunted', 'have', 'haven', 'having', 'hawaii', 'he', 'head', 'headache', 'headband', 'headed', 'headlights', 'heads', 'healthy', 'hear', 'heard', 'hearing', 'hears', 'heart', 'heavy', 'hegemony', 'height', 'heights', 'held', 'hello', 'helmet', 'help', 'helping', 'helps', 'her', 'here', 'herself', 'hey', 'hi', 'hid', 'hidden', 'hierarchy', 'high', 'highly', 'highway', 'hill', 'hills', 'him', 'himself', 'his', 'history', 'hit', 'hitchhiking', 'hits', 'hitting', 'hmm', 'hold', 'holding', 'holds', 'holes', 'home', 'homes', 'homework', 'honestly', 'honor', 'hooked', 'hope', 'hoped', 'hoping', 'horrible', 'horrified', 'horror', 'horse', 'horses', 'hospital', 'hospitals', 'host', 'hosted', 'hosting', 'hosts', 'hot', 'hotel', 'hotter', 'hour', 'hours', 'house', 'how', 'howard', 'however', 'huge', 'humid', 'humm', 'humming', 'humor', 'hundred', 'hung', 'hungry', 'hurricane', 'hurried', 'hurry', 'hurts', 'husband', 'husky', 'i', 'ibm', 'ice', 'idea', 'ideas', 'identified', 'identify', 'identities', 'identity', 'idiot', 'if', 'ignored', 'ill', 'illinois', 'illness', 'imagination', 'imagine', 'imagined', 'imagines', 'immediately', 'impacted', 'impatient', 'implant', 'implications', 'implicit', 'implies', 'impolite', 'important', 'impossible', 'improved', 'in', 'inches', 'include', 'included', 'including', 'incredulously', 'india', 'indiana', 'indicated', 'individual', 'individuals', 'infection', 'influence', 'influences', 'inform', 'information', 'informed', 'informing', 'informs', 'ingore', 'inhale', 'inhaled', 'initial', 'injections', 'injured', 'innocent', 'ins', 'inside', 'inspiring', 'instances', 'instead', 'institute', 'institutions', 'instructions', 'insurance', 'intelligence', 'intelligent', 'intelligible', 'intense', 'interested', 'interesting', 'international', 'internet', 'interpret', 'interpretated', 'interpretation', 'interpretations', 'interpreted', 'interpreter', 'interpreting', 'interprets', 'intersection', 'interstate', 'intervene', 'intervening', 'intervention', 'interview', 'interviewed', 'intimidating', 'into', 'introduce', 'introduced', 'introducing', 'introduction', 'invention', 'invitation', 'invite', 'invited', 'involve', 'involved', 'involvement', 'involves', 'involving', 'iowa', 'iowans', 'ipods', 'irish', 'ironic', 'irritating', 'is', 'isn', 'isnt', 'issues', 'it', 'italian', 'items', 'its', 'itself', 'jack', 'jail', 'jamaica', 'jana', 'jane', 'janet', 'jason', 'jen', 'jersey', 'jessica', 'jim', 'job', 'joe', 'john', 'join', 'joined', 'joining', 'joint', 'journal', 'journey', 'judge', 'judges', 'judging', 'judgment', 'judgments', 'juice', 'july', 'jumping', 'jumps', 'junior', 'just', 'k', 'ked', 'keep', 'keeps', 'kept', 'kernels', 'key', 'keys', 'kick', 'kicked', 'kicks', 'kid', 'kids', 'killed', 'kind', 'kinds', 'king', 'kitchen', 'knee', 'knew', 'know', 'knowing', 'known', 'knows', 'kudos', 'l', 'la', 'laboriously', 'lack', 'laid', 'lake', 'landed', 'landscaping', 'lane', 'language', 'languages', 'lapd', 'laptop', 'laptops', 'last', 'lasts', 'late', 'lately', 'later', 'laugh', 'laughed', 'laughing', 'laughter', 'lawn', 'lay', 'lays', 'lazy', 'lead', 'leader', 'learn', 'learned', 'learning', 'learns', 'least', 'leave', 'leaves', 'leaving', 'lecture', 'lecturing', 'led', 'left', 'leg', 'legal', 'less', 'lesson', 'let', 'letter', 'letters', 'letting', 'level', 'library', 'license', 'lid', 'lie', 'lied', 'lies', 'life', 'lifting', 'light', 'lightning', 'lights', 'like', 'liked', 'likes', 'liking', 'limit', 'limited', 'limp', 'lincoln', 'line', 'linguistics', 'link', 'lips', 'list', 'listen', 'listened', 'listens', 'lists', 'lit', 'literally', 'literature', 'littered', 'little', 'live', 'lived', 'lives', 'living', 'liz', 'll', 'loaf', 'local', 'located', 'location', 'locations', 'locked', 'locker', 'locks', 'log', 'logs', 'lombardi', 'lonely', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'loop', 'los', 'lose', 'losing', 'lost', 'lot', 'lotion', 'lots', 'lottery', 'loud', 'louder', 'loudly', 'lound', 'lousy', 'love', 'loves', 'lowered', 'lox', 'luck', 'lucky', 'lunch', 'lurches', 'lying', 'm', 'mac', 'machine', 'mad', 'made', 'magazine', 'magazines', 'mail', 'maine', 'maintained', 'make', 'makers', 'makes', 'making', 'mall', 'man', 'managed', 'manager', 'manila', 'many', 'maority', 'marathon', 'march', 'market', 'markets', 'married', 'mary', 'match', 'matches', 'math', 'matter', 'may', 'maybe', 'mayor', 'mc', 'mcdonald', 'mcdonalds', 'me', 'mean', 'meaning', 'meanings', 'means', 'meant', 'meat', 'mechanic', 'medication', 'medium', 'meet', 'meeting', 'meetings', 'member', 'memorizing', 'men', 'mentioned', 'mentor', 'menu', 'message', 'messed', 'messing', 'met', 'metal', 'meter', 'mexican', 'mexico', 'miami', 'mid', 'middle', 'might', 'mike', 'miles', 'milk', 'millions', 'mind', 'minded', 'mine', 'mingling', 'minnesota', 'minute', 'minutes', 'mischevious', 'misinterpretation', 'misinterpreted', 'miss', 'missed', 'missing', 'mistake', 'misunderstandings', 'misunderstood', 'mitt', 'mix', 'mixes', 'mmmmmm', 'mmmmmmm', 'model', 'mom', 'moment', 'monday', 'money', 'monitor', 'month', 'months', 'mood', 'moore', 'more', 'mormon', 'morning', 'most', 'mostly', 'mother', 'motivate', 'motivating', 'motor', 'motorcycle', 'motorcycles', 'motorcycling', 'mouse', 'mouth', 'mouths', 'move', 'moved', 'movie', 'movies', 'moving', 'mow', 'mowing', 'mph', 'mr', 'much', 'muffle', 'muhammad', 'muscles', 'music', 'must', 'mute', 'my', 'myself', 'n', 'nadal', 'nagivate', 'nah', 'nailed', 'nails', 'naked', 'name', 'named', 'names', 'nasal', 'natural', 'nauseated', 'nauseous', 'near', 'nearby', 'nearly', 'nebraska', 'necessarily', 'necessary', 'necessity', 'need', 'needed', 'needle', 'needs', 'negative', 'negatively', 'neglect', 'neglects', 'neighbor', 'neighbors', 'neither', 'nervous', 'netflix', 'nevada', 'never', 'new', 'news', 'newton', 'next', 'nice', 'night', 'nights', 'nightstick', 'nighttime', 'no', 'nobody', 'noise', 'noises', 'noisy', 'none', 'nope', 'norm', 'normal', 'normally', 'norms', 'north', 'northridge', 'not', 'notes', 'nothing', 'notice', 'noticed', 'notices', 'now', 'nowadays', 'ntid', 'nudged', 'numb', 'number', 'nurse', 'nyc', 'o', 'oakland', 'obama', 'obey', 'obeyed', 'objects', 'obliviously', 'observe', 'observed', 'obviously', 'occasion', 'occasionally', 'occurences', 'ocean', 'of', 'off', 'offense', 'offensive', 'offer', 'office', 'officers', 'often', 'oftentimes', 'oh', 'ohh', 'ohio', 'oil', 'oj', 'ok', 'okay', 'old', 'older', 'omaha', 'on', 'once', 'one', 'ones', 'online', 'only', 'onto', 'oozing', 'open', 'opened', 'opening', 'opens', 'opinion', 'opportunities', 'opportunity', 'options', 'or', 'oral', 'oralism', 'orange', 'order', 'orders', 'organizations', 'orientation', 'orientations', 'oriented', 'other', 'others', 'otherwise', 'our', 'out', 'outgoing', 'outing', 'outside', 'outta', 'over', 'overall', 'overnight', 'own', 'owns', 'pace', 'paddle', 'page', 'pageant', 'pager', 'pages', 'paid', 'pain', 'painting', 'paintings', 'pale', 'palin', 'panic', 'pans', 'pants', 'paper', 'papers', 'parents', 'park', 'parked', 'parker', 'parkf', 'parkinson', 'part', 'party', 'pass', 'passed', 'passes', 'past', 'pasta', 'path', 'pathway', 'patient', 'paul', 'pay', 'paying', 'pc', 'peanut', 'peanuts', 'pee', 'peed', 'peeing', 'peeked', 'peel', 'peeled', 'peeves', 'pen', 'people', 'perceive', 'percent', 'perfect', 'perfectly', 'perform', 'perhaps', 'permission', 'permitted', 'perpendicular', 'perry', 'person', 'persona', 'personal', 'personality', 'personally', 'perspective', 'persuit', 'pet', 'pete', 'petrone', 'phil', 'philadelphia', 'phone', 'phrase', 'physics', 'pick', 'picked', 'picking', 'picks', 'picture', 'pie', 'pieces', 'pies', 'pig', 'pigs', 'pile', 'pill', 'pineapple', 'piss', 'pissing', 'pitch', 'pitched', 'pizza', 'place', 'placed', 'places', 'plaid', 'plain', 'plan', 'plane', 'planned', 'planning', 'plans', 'plants', 'plastic', 'plate', 'play', 'played', 'player', 'players', 'playing', 'plays', 'please', 'pleased', 'plus', 'pm', 'pocket', 'pocketed', 'point', 'pointed', 'points', 'police', 'policies', 'policy', 'polite', 'politeness', 'politics', 'pond', 'pop', 'popcorn', 'popped', 'popping', 'positive', 'possible', 'possiblility', 'post', 'postcard', 'poster', 'postpone', 'potatoes', 'pots', 'potter', 'pounding', 'pounds', 'poured', 'pours', 'power', 'powerful', 'practically', 'praise', 'praised', 'precisely', 'prefer', 'preferred', 'prefers', 'pregnant', 'prepared', 'presence', 'presented', 'presenter', 'presenting', 'president', 'pressure', 'presumption', 'pretty', 'price', 'pries', 'primary', 'prince', 'principal', 'print', 'pro', 'probably', 'problem', 'problems', 'proceeded', 'process', 'proctor', 'products', 'professional', 'professionals', 'professor', 'proficient', 'profusely', 'progress', 'project', 'properly', 'properties', 'proven', 'provides', 'pry', 'public', 'puerto', 'pull', 'pulled', 'pulls', 'pump', 'pumpkin', 'punched', 'punches', 'punching', 'punished', 'punishment', 'puppet', 'puppies', 'purple', 'pushed', 'put', 'puts', 'putting', 'quality', 'quarterback', 'quesiton', 'question', 'questions', 'quick', 'quicker', 'quickly', 'quiet', 'quieter', 'quietly', 'quit', 'quiz', 'quote', 'r', 'ra', 'race', 'raft', 'rafting', 'raiders', 'rain', 'rained', 'raining', 'rains', 'rainy', 'raised', 'ran', 'rang', 'range', 'ranges', 'ranking', 'rapids', 'ras', 'rather', 'ray', 're', 'reached', 'reaches', 'react', 'read', 'reading', 'reads', 'ready', 'real', 'reality', 'realize', 'realized', 'realizing', 'reallhy', 'really', 'rear', 'reason', 'reasonaly', 'reassures', 'received', 'receiver', 'recently', 'recognize', 'recommend', 'record', 'records', 'red', 'reduce', 'refer', 'references', 'referred', 'reflects', 'refuse', 'refused', 'refuses', 'regarded', 'regathered', 'regret', 'regular', 'regularly', 'related', 'relates', 'relation', 'relationship', 'relaxed', 'released', 'relief', 'relieved', 'rely', 'remark', 'remarks', 'remember', 'remembering', 'remembers', 'remind', 'reminds', 'remove', 'removes', 'rent', 'rented', 'reopen', 'repairs', 'repeatedly', 'replaces', 'replacing', 'reply', 'report', 'reported', 'reporter', 'reporters', 'republican', 'require', 'required', 'requires', 'research', 'researches', 'reservation', 'residence', 'residences', 'resonance', 'resources', 'respect', 'responsible', 'restauarnt', 'restaurant', 'restaurants', 'resteraunt', 'result', 'resulted', 'results', 'resume', 'retire', 'return', 'ribs', 'rick', 'rico', 'ride', 'riding', 'right', 'ring', 'rip', 'ripped', 'rise', 'rises', 'risk', 'rit', 'river', 'road', 'rochester', 'rock', 'rodney', 'role', 'rollerbladed', 'rollerblades', 'romney', 'roof', 'room', 'roommate', 'roommates', 'rope', 'rose', 'roses', 'route', 'row', 'rowdy', 'rowing', 'rsd', 'rubber', 'rude', 'rules', 'rummaged', 'run', 'running', 'runs', 'rushes', 'rustle', 'rustling', 'ruthless', 's', 'sack', 'sad', 'safe', 'safely', 'said', 'sale', 'sally', 'same', 'san', 'sanctuary', 'sandwich', 'sank', 'sanucatory', 'sarah', 'sarcastically', 'sat', 'save', 'saw', 'say', 'saying', 'says', 'scare', 'scared', 'scary', 'scheduled', 'school', 'schooled', 'scissors', 'score', 'scout', 'scratched', 'scratching', 'scream', 'screamed', 'screaming', 'screening', 'seafood', 'seal', 'seasons', 'seat', 'seats', 'seattle', 'second', 'security', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'seles', 'sell', 'semester', 'send', 'sends', 'senior', 'sense', 'sensed', 'senses', 'sensory', 'sent', 'sentence', 'separated', 'separating', 'september', 'serious', 'serve', 'service', 'services', 'serving', 'session', 'set', 'sets', 'setting', 'settled', 'seven', 'several', 'sewer', 'sexual', 'sf', 'shake', 'shaken', 'shakes', 'shaking', 'shampoo', 'share', 'shared', 'shares', 'sharing', 'sharp', 'sharpova', 'she', 'sheep', 'shh', 'shines', 'shining', 'shirt', 'shirts', 'shitfaced', 'shock', 'shocked', 'shoes', 'shone', 'shook', 'shoots', 'shop', 'shopping', 'shore', 'short', 'shorts', 'shot', 'should', 'shoulder', 'shouldn', 'show', 'showed', 'shower', 'shown', 'shows', 'shrit', 'shut', 'siberian', 'sick', 'sickness', 'side', 'sigh', 'sign', 'signed', 'signer', 'signing', 'signs', 'silber', 'silent', 'silk', 'silly', 'similar', 'similarly', 'simple', 'simply', 'since', 'siren', 'sister', 'sit', 'sites', 'sitting', 'situation', 'situations', 'six', 'size', 'sized', 'sizes', 'ski', 'skidding', 'skiing', 'skills', 'slammed', 'slaughtering', 'sleep', 'sleeping', 'sleeps', 'sleeves', 'slept', 'sliced', 'slide', 'slings', 'slow', 'slower', 'slowly', 'slumped', 'small', 'smaller', 'smart', 'smashed', 'smell', 'smirk', 'smoking', 'smooth', 'smoothly', 'snatch', 'sneak', 'snobby', 'snow', 'snowing', 'snows', 'snuck', 'so', 'social', 'socialize', 'socialized', 'socially', 'sold', 'some', 'somebody', 'someone', 'something', 'sometimes', 'somewhere', 'son', 'song', 'soon', 'sore', 'sorry', 'sort', 'sound', 'sounded', 'sounds', 'soup', 'south', 'spa', 'span', 'spare', 'speak', 'speakers', 'speaking', 'speaks', 'special', 'specialist', 'specialists', 'specific', 'spectrum', 'spedometer', 'speech', 'speed', 'spell', 'spend', 'spent', 'spinach', 'spit', 'spoiled', 'spoke', 'sport', 'sports', 'spots', 'sprained', 'spray', 'spring', 'spun', 'st', 'staff', 'stall', 'stamps', 'stand', 'standing', 'stare', 'stared', 'staring', 'start', 'started', 'starting', 'starts', 'state', 'states', 'station', 'status', 'stay', 'stayed', 'staying', 'stays', 'steak', 'steam', 'stems', 'stewart', 'sticky', 'stiill', 'still', 'stitched', 'stitches', 'stitching', 'stole', 'stolen', 'stomach', 'stood', 'stop', 'stopped', 'stopping', 'stops', 'store', 'stories', 'storm', 'story', 'straight', 'strange', 'strangers', 'strategy', 'stratiy', 'strict', 'strikes', 'string', 'strip', 'striped', 'stripes', 'strong', 'struck', 'struggled', 'struggles', 'struggling', 'stuck', 'student', 'students', 'studies', 'study', 'studying', 'styrofoam', 'subsequent', 'subtelny', 'succeed', 'succeeds', 'succesfully', 'successful', 'such', 'sudden', 'suddenly', 'sue', 'suggest', 'suiting', 'summer', 'summons', 'sun', 'sunbathe', 'sunbathing', 'sunburn', 'sunday', 'sundown', 'sunny', 'sunrise', 'sunscreen', 'sunset', 'suntan', 'super', 'superior', 'superiority', 'support', 'supporting', 'suppose', 'supposed', 'supreme', 'sure', 'surf', 'surface', 'surfing', 'surgeon', 'surprise', 'surprised', 'surprises', 'survive', 'sushi', 'suspected', 'swam', 'swashbuckler', 'sweetheart', 'swerved', 'swim', 'swimming', 'swinging', 'switch', 'switched', 'switching', 'syntax', 'system', 'systems', 't', 'table', 'tables', 'taboo', 'tactic', 'tactile', 'tag', 'tail', 'take', 'takes', 'taking', 'talk', 'talked', 'talking', 'talks', 'tall', 'tan', 'tank', 'tape', 'tapes', 'tapped', 'tappee', 'tapper', 'taps', 'tasks', 'taste', 'tasted', 'tastes', 'taught', 'tea', 'teach', 'teacher', 'teachers', 'team', 'teams', 'tease', 'teasing', 'technology', 'teddy', 'television', 'tell', 'telling', 'tells', 'tempo', 'tempted', 'ten', 'tend', 'tended', 'tendency', 'tends', 'tennessee', 'tennis', 'tense', 'tents', 'term', 'terminal', 'terrible', 'terribly', 'test', 'testimonies', 'texas', 'text', 'texting', 'than', 'thank', 'thanking', 'thanks', 'that', 'thats', 'the', 'theater', 'theatre', 'their', 'them', 'themselves', 'then', 'there', 'therefore', 'these', 'they', 'thick', 'thief', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'thirdly', 'thirteen', 'thirty', 'this', 'those', 'though', 'thought', 'thousand', 'thousands', 'threatened', 'threatening', 'three', 'threw', 'thrilled', 'throat', 'through', 'throughout', 'throw', 'thrown', 'throws', 'thrusts', 'thursday', 'ticked', 'ticket', 'tickets', 'tie', 'tied', 'tigers', 'tight', 'til', 'time', 'times', 'tiny', 'tire', 'tired', 'tires', 'to', 'today', 'together', 'toilet', 'told', 'tomorrow', 'tone', 'tonight', 'tons', 'tony', 'too', 'took', 'tool', 'top', 'topic', 'toppings', 'torn', 'tossed', 'total', 'touch', 'touchdown', 'tough', 'tougher', 'toward', 'towards', 'toys', 'tracking', 'trader', 'tradition', 'traffic', 'train', 'trained', 'transfer', 'transferred', 'travel', 'traveled', 'traveling', 'travelling', 'travels', 'tray', 'treating', 'tree', 'trees', 'trickiling', 'tried', 'trigger', 'trip', 'trouble', 'truck', 'true', 'trunk', 'trust', 'truth', 'try', 'trying', 'tubing', 'turn', 'turned', 'turning', 'turns', 'tv', 'twelve', 'twenty', 'twice', 'two', 'types', 'typical', 'tyranny', 'u', 'ugh', 'ugly', 'uh', 'umbrella', 'umbrellas', 'uncertain', 'uncle', 'uncontrollable', 'under', 'underage', 'underlying', 'understand', 'understood', 'undoubtedly', 'uneasy', 'unfinished', 'unfortunately', 'uniform', 'university', 'unless', 'unpredictable', 'unsatified', 'until', 'untill', 'up', 'upon', 'upset', 'upstairs', 'urinate', 'urinated', 'urinating', 'us', 'usage', 'use', 'used', 'uses', 'using', 'usually', 'utah', 'utter', 'utterly', 'vacation', 'vacations', 'value', 'variations', 'varies', 'variety', 'various', 'vary', 've', 'vegetable', 'vegetables', 'vegetarian', 'ventriloquism', 'vermont', 'very', 'via', 'vibrating', 'victim', 'video', 'videogame', 'videophoning', 'videotape', 'view', 'viewed', 'viewing', 'vince', 'violently', 'vision', 'visit', 'visited', 'visiting', 'visits', 'vists', 'visual', 'visualize', 'visualized', 'vocal', 'vocalization', 'vocalizations', 'vocals', 'voice', 'voices', 'volunteer', 'vomiting', 'vomitting', 'vote', 'voucher', 'vp', 'wait', 'waited', 'waiters', 'waiting', 'waitress', 'waive', 'wake', 'walk', 'walked', 'walking', 'walks', 'wallet', 'want', 'wanted', 'wants', 'wards', 'warm', 'warmly', 'warn', 'warned', 'warning', 'warnings', 'was', 'wash', 'washed', 'wasn', 'wasnt', 'waste', 'wasting', 'watch', 'watched', 'watches', 'watching', 'water', 'wave', 'waved', 'waves', 'waving', 'way', 'ways', 'we', 'wear', 'wearing', 'wears', 'weather', 'web', 'websites', 'wedding', 'week', 'weekend', 'weekends', 'weigh', 'weight', 'weights', 'weird', 'welcome', 'welcoming', 'well', 'went', 'were', 'weren', 'wet', 'what', 'whatever', 'wheel', 'when', 'whenever', 'where', 'whereas', 'whether', 'which', 'whichever', 'while', 'whipping', 'white', 'who', 'whoa', 'whoever', 'whole', 'whom', 'whose', 'why', 'wide', 'wife', 'will', 'willing', 'willis', 'win', 'winding', 'window', 'windows', 'winner', 'winning', 'wins', 'winter', 'wintertime', 'wish', 'with', 'within', 'without', 'witty', 'wnt', 'woke', 'woken', 'wolf', 'woman', 'won', 'wonder', 'wondered', 'wonderful', 'wondering', 'wood', 'word', 'words', 'work', 'worked', 'worker', 'working', 'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'wrapped', 'wrestle', 'wrestling', 'write', 'writing', 'written', 'wrong', 'wrote', 'wymoing', 'wymoning', 'wyoming', 'x', 'yards', 'yawned', 'year', 'years', 'yell', 'yelled', 'yelling', 'yes', 'yesterday', 'yet', 'york', 'you', 'young', 'your', 'yourself', 'yuck', 'zipped', 'zombie', 'zone', '—', '“', '”', '…']\n",
      "asl_tokens ['#', '(', ')', '+', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>', 'A', 'A-LEVEL-ABOVE', 'A-LEVEL-BELOW', 'A-LOT', 'A-OK', 'A-WAYS', 'ABANDON', 'ABOUT', 'ABOVE', 'ABUSE', 'AC', 'ACCEPT', 'ACCIDENT', 'ACCOMMODATE', 'ACROSS', 'ACT', 'ACTION', 'ADD-TO', 'ADDICTED', 'ADMIT', 'ADULT-TALL', 'ADVANTAGE', 'ADVENTURE', 'ADVISE', 'ADVISE/INFLUENCE', 'ADVISER', 'AFRAID', 'AFTER', 'AFTERNOON', 'AGAIN', 'AGAINST', 'AGE', 'AGE-SIX', 'AGE-TWENTY-ONE', 'AGENT', 'AGREE', 'AIR', 'AIRPLANE', 'ALARM', 'ALCOHOL', 'ALEC-BALDWIN', 'ALI', 'ALL', 'ALL-DAY', 'ALL-GONE', 'ALL-NIGHT', 'ALL-THE-WAY', 'ALL-YEARS-HS', 'ALLERGY', 'ALLOW', 'ALMOST', 'ALONE', 'ALRIGHT', 'ALSO', 'ALWAYS', 'AMONG', 'AMY', 'ANALYZE', 'AND', 'ANGRY', 'ANIMAL', 'ANKLE', 'ANN', 'ANNOUNCE', 'ANSWER', 'ANY', 'ANYWAY/NOT-MATTER', 'APPEAR', 'APPLAUSE', 'APPLE', 'APPLY', 'APPOINTMENT', 'APPROACH', 'APT', 'AREA', 'ARGUE', 'AROUND', 'ARREST', 'ARRIVE', 'ARTICLE', 'ASIA', 'ASK', 'ASL', 'ASS', 'ASSAULT', 'ASSISTANT', 'AT', 'ATTEMPT', 'ATTENTION-WAVE', 'AUDIO', 'AUDIOVOCAL', 'AUNT', 'AUSTRALIA', 'AUTUMN', 'AVERAGE', 'AVERAGE/RANGE', 'AWFUL', 'AWKWARD', 'B', 'B-L', 'BABY', 'BACK', 'BACK-TO-TOPIC', 'BAD', 'BAG', 'BAGEL', 'BAGS', 'BAKE/OVEN', 'BALANCE', 'BALD', 'BALL', 'BANDAGE', 'BANKS', 'BARACK-OBAMA', 'BARBARIC', 'BARITONE', 'BASEBALL', 'BASKETBALL', 'BATHROOM', 'BAUMAN', 'BAWL-OUT', 'BBQ', 'BCL', 'BE', 'BEACH', 'BEAR', 'BEAUTIFUL', 'BECAUSE', 'BECOME', 'BED', 'BEER', 'BEFORE', 'BEHIND', 'BEING', 'BELIEVE', 'BELONG', 'BELT', 'BEN', 'BERRY', 'BEST', 'BETH', 'BETTER', 'BETWEEN', 'BETWEEN/SHARE', 'BEVERLY', 'BIB', 'BICYCLE', 'BIG', 'BIGGER', 'BILL', 'BILL/OWE', 'BIRD', 'BIRTHDAY', 'BLACK', 'BLADDER', 'BLAME', 'BLANK-OUT', 'BLOCK', 'BLOOD', 'BLOW', 'BLOWN-AWAY', 'BLUE', 'BOAT', 'BOB', 'BODY', 'BOMB', 'BONE', 'BONFIRE', 'BOOK', 'BOOK-PAGE', 'BOOT', 'BORDER', 'BORE', 'BORN', 'BORROW', 'BOSS', 'BOSTON', 'BOTH', 'BOTHER', 'BOX', 'BOX/ROOM', 'BOXER', 'BOXING', 'BOY', 'BPC', 'BPCL', 'BQQ', 'BRACELET', 'BRAKE', 'BRAVE/RECOVER', 'BREAD', 'BREAK', 'BREAK-DOWN', 'BREAKFAST', 'BREATHE', 'BRICK', 'BRIDE', 'BRING', 'BROCCOLI', 'BROOKLINE', 'BROTHER', 'BROWN', 'BRUCE-WILLIS', 'BUBBLES', 'BUILD', 'BUILDING', 'BUOY', 'BURN', 'BURP', 'BURST', 'BUS', 'BUSH', 'BUSINESS', 'BUSTED', 'BUT', 'BUTCHER-SHOP', 'BUTTER', 'BUTTS', 'BUY', 'BY', 'C', 'C-L', 'CABIN', 'CAFETERIA', 'CALIFORNIA', 'CALL', 'CALL-BY-PHONE', 'CAMP', 'CAN', 'CANCEL/CRITICIZE', 'CANCER', 'CANDY', 'CANNOT', 'CAPE-COD', 'CAPECOD', 'CAR', 'CARD', 'CARE', 'CAREER', 'CAROL', 'CARRY', 'CASINO', 'CAT', 'CAUCUS', 'CAUSE', 'CAVIAR', 'CD', 'CELEBRATE', 'CEREAL', 'CHAIR', 'CHALLENGE', 'CHANGE', 'CHANNEL', 'CHARACTER', 'CHARLES', 'CHASE', 'CHAT', 'CHEAP', 'CHECK', 'CHEER', 'CHEESE', 'CHEMICAL', 'CHESS', 'CHICAGO', 'CHICKEN', 'CHILDREN', 'CHINA', 'CHOCOLATE', 'CHOICE', 'CHOOSE', 'CHOP', 'CHURCH', 'CIGARETTE', 'CITY/COMMUNITY', 'CL', 'CNN', 'COACH', 'COAT', 'COCHLEAR-IMPLANT', 'CODA', 'CODE', 'COFFEE', 'COFFIN', 'COLD', 'COLLAR', 'COLLARS', 'COLLEAGUE', 'COLLECT', 'COLLEGE', 'COLLIDED', 'COLOR', 'COLORADO', 'COME', 'COME-ON', 'COMFORTABLE', 'COMMUNICATE', 'COMMUTE', 'COMPANY', 'COMPARE', 'COMPETITION', 'COMPUTER', 'CONCEPT', 'CONDUCT', 'CONFIDENT', 'CONFLICT/INTERSECTION', 'CONFRONT', 'CONFUSE', 'CONTACT', 'CONTINUE', 'COOK', 'COOK/KITCHEN', 'COOKIE', 'COOL', 'COOLER', 'COOPERATE/UNITE', 'COORDINATOR', 'COP', 'COPY', 'CORN', 'CORNER', 'CORRECT', 'COUGH', 'COUNT-ON-FINGERS', 'COUNTRY', 'COURSE', 'COURT', 'COUSIN', 'COW', 'CPR', 'CRACK', 'CRASH', 'CRAZY', 'CREAM', 'CREATE/PRETEND', 'CREEPY', 'CRIB', 'CRISIS', 'CROPS', 'CROWDED', 'CRY', 'CSUN', 'CUED-SPEECH', 'CULTURE', 'CUP', 'CUT', 'CUTE', 'CUTTER', 'D', 'DAISY', 'DANA', 'DANCE', 'DANGER', 'DARK', 'DATE', 'DATE/DESSERT', 'DAUGHTER', 'DAY', 'DCL', 'DEAD', 'DEAF', 'DEAF-APPLAUSE', 'DEAN', 'DEC', 'DECIDE', 'DECORATE', 'DEEP', 'DEER', 'DEGREE', 'DELETE', 'DELIBERATE', 'DELICIOUS', 'DEMI-MOORE', 'DEMOCRAT', 'DEPART', 'DEPRESS', 'DESTROY', 'DEVELOP', 'DEVIL', 'DIE', 'DIFFERENT', 'DIMWITTED', 'DINNER', 'DIRECT', 'DIRECT/EXPLAIN', 'DISAPPOINT', 'DISCIPLINE', 'DISCONNECT', 'DISCUSS', 'DISCUSS-INTENSELY', 'DISEASE', 'DISGUST', 'DISORDER', 'DISORDERED', 'DISTRIBUTE', 'DO', 'DO-DO', 'DO-IT', 'DOCTOR', 'DOG', 'DOING', 'DOLLAR', 'DONNA', 'DONUT', 'DOOR', 'DORM', 'DOUBT', 'DOWN', 'DOWN-THE-LIST', 'DOWNHILL', 'DRAMA', 'DREAM', 'DRESS/CLOTHES', 'DRINK', 'DRIVE', 'DROP', 'DRUG', 'DRUGS', 'DRUNK', 'DRY', 'DRY-CEREAL', 'DURING/WHILE', 'DVD', 'DYE', 'E', 'EACH', 'EAN', 'EAR', 'EARLY', 'EASIER', 'EASY', 'EAT', 'EAT-UP', 'ECONOMIC', 'ED', 'EIGHT', 'EIGHTY', 'ELECTION', 'ELEVEN', 'ELITE', 'EMAIL', 'EMBARRASS', 'EMERGENCY', 'EMIT', 'EMOTION', 'EMPTY', 'EMPTY-FROM-NOW-ON', 'EMPTY/EARLY', 'END', 'ENGINE', 'ENGLISH', 'ENJOY', 'ENNIS', 'ENOUGH', 'ENTER', 'ENVIRONMENT', 'EQUAL', 'ERICK', 'ESCAPE', 'ETC.', 'EUROPE', 'EVEN', 'EVER', 'EVERY', 'EVERY-MONTH/RENT', 'EVERY-MORNING', 'EVERY-YEAR', 'EVERYDAY', 'EX', 'EXACT', 'EXAM', 'EXAMPLE', 'EXCESS', 'EXCHANGE', 'EXCITE', 'EXCITED', 'EXCUSE', 'EXCUSE-GO', 'EXHAUST', 'EXPECT', 'EXPENSIVE', 'EXPERIENCE', 'EXPERIMENT', 'EXPERT', 'EXPLAIN', 'EXPRESS', 'EXTEND', 'EYES', 'F', 'FACE', 'FAIL', 'FALL', 'FALL-ASLEEP', 'FALL-IN-LOVE', 'FALL-INTO-IT', 'FALL-INTO-PLACE', 'FAMILY', 'FAMOUS', 'FAN', 'FANCY', 'FANS', 'FAR', 'FARM', 'FART', 'FASCINATED', 'FAST', 'FATHER', 'FAVORITE/PREFER', 'FEDERATION', 'FEDEX', 'FEED', 'FEEL', 'FEET', 'FENCE', 'FEW', 'FEW/CLOSE', 'FF', 'FIELD', 'FIFTEEN', 'FIFTH-IN-LIST', 'FIGHT', 'FILL-OUT', 'FILM', 'FINALLY/SUCCEED', 'FIND', 'FIND/FIND-OUT', 'FINE', 'FINISH', 'FIRE', 'FIRED', 'FIREWORKS', 'FIRST', 'FIRST-IN-LIST', 'FIRST-SECOND-THIRD-IN-LIST', 'FISH', 'FISHING', 'FIVE', 'FIVE-MINUTE', 'FIX', 'FLA', 'FLAT', 'FLAT/FLOOR', 'FLAT/LEVEL', 'FLOOD', 'FLOOR', 'FLOW', 'FLOWER', 'FLUSH', 'FLY-BY-PLANE', 'FOCUS', 'FOCUS/NARROW', 'FOLLOW', 'FOOD', 'FOOT', 'FOOTBALL', 'FOR', 'FOR-FOR', 'FOREVER', 'FORGET', 'FORGET-IT', 'FORK', 'FORMERLY', 'FORTUNATELY', 'FOUR', 'FOUR-DAY', 'FOUR-THIRTY', 'FOURTH', 'FOURTH-IN-LIST', 'FRANCE', 'FRANK', 'FRATERNITY', 'FREAK', 'FREE', 'FREQUENTLY', 'FRESH', 'FRESHMAN', 'FRIDAY', 'FRIEND', 'FRIENDLY', 'FRISBEE', 'FROM', 'FROM-NOW-ON', 'FRONT', 'FRUGAL', 'FRUIT', 'FS-ZONE', 'FUCK', 'FULL', 'FUMBLE', 'FUN', 'FUNNY', 'FUTURE', 'G', 'G/Q', 'GALLAUDET', 'GAMBLE', 'GAME', 'GAMUT', 'GARAGE/SUBMARINE', 'GAS', 'GAZPACHO', 'GENERAL', 'GEORGE-BUSH', 'GEORGE-CLOONEY', 'GERMANY', 'GESTURE', 'GET', 'GET-IN', 'GET-IN-BED', 'GET-TICKET', 'GET-UP', 'GHOST', 'GI', 'GIF', 'GIFT', 'GILBERT', 'GIRL', 'GIV', 'GIVE', 'GIVE-UP', 'GLOBE', 'GO', 'GO-AHEAD', 'GO-AWAY', 'GO-BY-BOAT', 'GO-OUT', 'GOAL', 'GOBBLE-UP', 'GOD', 'GOLD', 'GOLD/CALIFORNIA', 'GOLF', 'GONE', 'GOOD', 'GOOD/THANK-YOU', 'GRAB', 'GRAB-CHANCE', 'GRADUAL-IMPROVE', 'GRADUATE', 'GRANDFATHER', 'GRANDMOTHER', 'GRASS', 'GREAT', 'GREATECHWAECH', 'GREEN', 'GRIEF', 'GROOM', 'GROUND', 'GROUP', 'GROUP/TOGETHER', 'GROW', 'GROW-UP', 'GRUNT', 'GRUNTAL', 'GRUNTS', 'GUARANTEE', 'GUESS', 'GUEST', 'GUITAR', 'H', 'HAIR', 'HALF', 'HALL', 'HAMBURGER', 'HANDLE', 'HANG-UP-PHONE', 'HAPPEN', 'HAPPY', 'HARD', 'HARRY', 'HATE', 'HAVE', 'HAVE-TO', 'HEAD', 'HEAD-COLD', 'HEAD-TRIP', 'HEADACHE', 'HEAR', 'HEAR/LISTEN', 'HEARING', 'HEART', 'HEAVY', 'HEGEMONY', 'HEIGHT', 'HELMET', 'HELP', 'HER', 'HERE', 'HIDE', 'HIGH', 'HIGHWAY', 'HILL', 'HILLS', 'HISTORY', 'HIT', 'HITCH-HIKE', 'HOLD', 'HOME', 'HOMEWORK', 'HONEST', 'HONOR', 'HOPE', 'HORRIFIED', 'HORROR', 'HORSE', 'HOSPITAL', 'HOT', 'HOTEL', 'HOUR', 'HOURS', 'HOUSE', 'HOW', 'HOW-MANY', 'HOWARD', 'HS', 'HUMAN', 'HUMB-IX', 'HUMID', 'HUMOR', 'HUNGRY', 'HUNGRY/WISH', 'HURRICANE', 'HURRY', 'HURT', 'HUSBAND', 'I', 'IBLE', 'IBM', 'ICE-CREAM', 'ICK', 'ICL', 'IDEA', 'IDENTIFY', 'IDIOT', 'IF', 'IGNORE', 'ILL', 'IMAGINE', 'IMB', 'IMPACT', 'IMPLICATION', 'IMPLY', 'IMPORTANT', 'IMPOSSIBLE', 'IN', 'INCLUDE/ALL-INCLUDED', 'INCLUDE/INVOLVE', 'INCREASE', 'IND', 'INDIA', 'INDIVIDUAL', 'INFORM', 'INFORM-ALL', 'INFORMATION', 'INHALE', 'INJECT', 'INNOCENT', 'INSPIRE', 'INSTITUTE', 'INSURANCE/INFECTION', 'INTELLIGIBLE', 'INTERACT/COMMUNICATE', 'INTERCOURSE', 'INTERESTING', 'INTERNATIONAL', 'INTERNET', 'INTERPRET', 'INTERRUPT', 'INTERVIEW', 'INTIMIDATING', 'INTRODUCE', 'INVITE', 'INVITE/HIRE', 'INVOLVE', 'IOWA', 'IOWANS', 'IPOD', 'IS', 'IT', 'ITS', 'IX', 'J', 'JACK', 'JAIL', 'JAMAICA', 'JANA', 'JANE', 'JANET', 'JASON', 'JEN', 'JESSICA', 'JIM', 'JOB', 'JOE', 'JOHN', 'JOHN-STEWART', 'JOIN', 'JOINT', 'JOURNEY', 'JUICE', 'JULY', 'JUMP', 'K', 'KEEP', 'KERNEL', 'KEY', 'KICK-OFF', 'KICK-OUT', 'KID', 'KILL', 'KIND', 'KING', 'KISS-FIST', 'KITCHEN', 'KNEE', 'KNOW', 'KNOW-NOTHING', 'KNOW-THAT', 'KOWTOW', 'L', 'L-X', 'LA', 'LAKE', 'LANDSCAPE', 'LANDSCAPING', 'LANGUAGE', 'LAPD', 'LAPTOP', 'LAST', 'LAST-WEEK', 'LAST-YEAR', 'LATE', 'LATER', 'LAUGH', 'LAUGH-HARD', 'LAZY', 'LCL', 'LEAD', 'LEADER', 'LEAF', 'LEARN', 'LEAVE', 'LEAVE-THERE', 'LECTURE', 'LEG', 'LEGAL/LAW', 'LEND', 'LESS', 'LESS-THAN', 'LETTER/MAIL', 'LIBRARY', 'LICENSE', 'LIE', 'LIE-DOWN', 'LIFE', 'LIGHT', 'LIGHT-FLASH', 'LIGHT-MATCH', 'LIGHTNING', 'LIKE', 'LIMIT', 'LINCOLN', 'LINE', 'LINGUISTICS', 'LINK', 'LIP', 'LIST', 'LIST-NAMES', 'LIST-ORDER', 'LIST-ORDER-IX', 'LISTEN', 'LIT', 'LITTLE-BIT', 'LIVE', 'LIZ', 'LOCAL', 'LOCK', 'LOCKER', 'LOCKERS', 'LODI', 'LOG', 'LOGS', 'LOMBARDI', 'LOMBIDI', 'LOMDI', 'LONG', 'LONG-AGO', 'LONG-LIST', 'LONG-PAST', 'LONG-SLEEVE', 'LONG-TERM', 'LOOK', 'LOOK-AROUND', 'LOOK-AT', 'LOOK-BACK', 'LOOK-BY-EYE', 'LOOK-DOWN', 'LOOK-FOR', 'LOOK-FORWARD', 'LOOK-LIKE', 'LOOK-OVER', 'LOOK-UP', 'LOOP', 'LOSE', 'LOSE-COMPETITION', 'LOTION', 'LOTTERY', 'LOUD', 'LOUSY', 'LOVE', 'LOW/LOWER', 'LOWERCASE/TINY', 'LOX', 'LUCK', 'LUCKY', 'LVINCE', 'LY', 'M', 'MAC', 'MACHINE', 'MAD', 'MAGAZINE', 'MAIL', 'MAINE', 'MAJOR', 'MAKE', 'MAKE-IT', 'MAKER', 'MALE-COUSIN', 'MALL', 'MAN', 'MANAGE/CONTROL', 'MANILA', 'MANIPULATE', 'MANY', 'MARATHON', 'MARKET', 'MARRY', 'MARY', 'MATCH', 'MAYBE', 'MCDONALD', 'MEAN', 'MEANING-LIST', 'MEAT', 'MEDICINE', 'MEDIUM', 'MEET', 'MEETING', 'MELON/PUMPKIN', 'MELT/SOLVE', 'MEMBER', 'MEMORIZE', 'MENTION', 'MENTOR', 'MENU', 'MESSED-UP', 'METAL', 'MEXICO/SPAIN', 'MICROPHONE', 'MIDDLE', 'MIKE', 'MILES', 'MILK', 'MILLION', 'MIND', 'MINUTE', 'MINUTES', 'MISMATCH', 'MISS', 'MISS/ASSUME', 'MISTAKE', 'MISUNDERSTAND', 'MITT-ROMNEY', 'MODEL', 'MONDAY', 'MONEY', 'MONSTER', 'MOOD', 'MORE', 'MORMON', 'MORNING', 'MOST', 'MOST-SKILLED', 'MOTHER', 'MOTIVATE', 'MOTORCYCLE', 'MOUSE/FICTION', 'MOVE', 'MOVE-AROUND', 'MOVE-AWAY', 'MOVIE', 'MOVING-ON-TO-NEXT-TOPIC', 'MOW', 'MP', 'MPH', 'MR', 'MUCH', 'MUFFLE', 'MUHAMMAD', 'MUSIC', 'MUST', 'MUTE', 'N', 'NAB', 'NAKED', 'NAME', 'NARROW-STREET', 'NASAL', 'NATURAL', 'NAUSEA', 'NEAR', 'NEAT', 'NEB', 'NEED', 'NEG', 'NEGATIVE', 'NEGLECT', 'NERVOUS', 'NETFLIX', 'NEV', 'NEVADA', 'NEVER', 'NEW', 'NEW-YORK', 'NEWS', 'NEWTON', 'NEXT', 'NEXT-TO', 'NEXT-WEEK', 'NICE', 'NICE/CLEAN', 'NIGHT', 'NINE', 'NINETY', 'NINETY-SIX', 'NO', 'NO-GOOD', 'NOISE', 'NOISY', 'NONE', 'NONE/NOTHING', 'NOON', 'NORMAL', 'NORTH', 'NORTHRIDGE', 'NOSE', 'NOT', 'NOT-CARE', 'NOT-KNOW', 'NOT-LIKE', 'NOT-MIND', 'NOT-WANT', 'NOT-YET', 'NOTHING', 'NOTHING-AT-ALL', 'NOTICE', 'NOW', 'NOW-WEEK', 'NUMB', 'NUMBER', 'NURSE', 'NUT', 'NYC', 'O', 'OAKLAND', 'OBAMA', 'OBVIOUS', 'OCCASIONALLY', 'OCEAN', 'OF', 'OF-COURSE', 'OFF', 'OFFENSE', 'OFFICE', 'OFFICERS', 'OFTEN', 'OH', 'OH-I-SEE', 'OHIO', 'OIL', 'OJ', 'OK', 'OLD', 'OLDER', 'OMAHA', 'ON', 'ON-TIME', 'ONCE', 'ONCE-IN-A-WHILE', 'ONE', 'ONE-DOLLAR', 'ONE-HOUR', 'ONE-MONTH', 'ONE-THOUSAND', 'ONLY', 'OPEN', 'OPEN-BOOK', 'OPINION', 'OPPORTUNITY', 'OPPOSITE', 'OPTION', 'OR', 'ORANGE', 'ORGANIZATION', 'ORIENTATION', 'ORIENTED', 'OSE', 'OSE-BOOK', 'OSE-CALL', 'OSE-DOOR', 'OSE-GATE', 'OTHER', 'OUT', 'OUTGOING', 'OUTSIDE', 'OVER-IT', 'OVER-NIGHT', 'OVER/AFTER', 'OWN', 'P', 'PACE', 'PACE/PROGRESS', 'PACK', 'PADDLE/CANOE', 'PAGEANT', 'PAGER', 'PAINT', 'PALE', 'PANS', 'PANT', 'PAPER', 'PAPER-CHECK/CARD', 'PARADE', 'PARALLEL', 'PARK', 'PARKINSONS', 'PARPF', 'PART', 'PARTY', 'PARTY-HARD', 'PASS', 'PASS-DOWN', 'PAST', 'PATIENT', 'PAUL', 'PAY', 'PAY-ATTENTION', 'PAY/BUY', 'PAY/SPEND', 'PC', 'PCL', 'PEE', 'PEN', 'PEOPLE', 'PERCENT', 'PERFECT', 'PERMIT', 'PERSON', 'PERSONA', 'PET-PEEVE', 'PET/SPOILED', 'PETE', 'PHIL', 'PHILADELPHIA', 'PHONE', 'PICK-UP', 'PICK/CHOOSE', 'PICK/SELECT', 'PICTURE', 'PIE', 'PIG', 'PINEAPPLE', 'PING-PONG/TENNIS', 'PISS', 'PISS-OFF', 'PITCH', 'PITCH-IN', 'PITCHED', 'PITY', 'PKSON', 'PLACE', 'PLAID', 'PLAN', 'PLANT', 'PLASTIC', 'PLAY', 'PLAY-AGAINST', 'PLAYER', 'PLAYS', 'PLUS', 'PO', 'POINT', 'POINT-TO', 'POLE', 'POLICY', 'POLITE', 'POLITICS', 'PONDER', 'POP', 'POP-UP', 'POPCORN', 'POSITIVE', 'POSS', 'POSTER', 'POSTPONE', 'POTATO', 'POTS', 'POTTER', 'POUND', 'POUR-SWEAT', 'POWER', 'POWERFUL', 'PRACTICE', 'PREDICT', 'PREFER', 'PREGNANT', 'PRESENCE', 'PRESIDENT', 'PRESSURE', 'PRETEND', 'PRETTY', 'PRICE', 'PRINCE', 'PRINCIPAL', 'PRINT', 'PRO', 'PROBLEM', 'PROCEED', 'PROCTOR', 'PRODUCT', 'PROFESSION', 'PROGRESS', 'PROJECT', 'PROPORTION', 'PROVE', 'PUBLIC', 'PUERTO-RICO', 'PULL', 'PUMP', 'PUNCH', 'PUNISH', 'PUPPIES', 'PURPLE', 'PUSH', 'PUT', 'PUT-AWAY', 'QB', 'QM', 'QUALITY', 'QUARTERBACK', 'QUESTION', 'QUIET', 'QUIT', 'QUIZ', 'QUOTE', 'QUOTE/TOPIC', 'R', 'RA', 'RAFT', 'RAIDERS', 'RAIN', 'RAKE', 'RANGE', 'RANGE/SPAN', 'RE', 'READ', 'READY', 'REALIZE', 'REALLY', 'REASON', 'RECENT-PAST', 'RECORD', 'RED', 'REFUSE', 'REGULAR', 'RELATIONSHIP', 'RELATIONSHIP-OFF', 'RELAX', 'REMEMBER', 'REMIND', 'REMOTE', 'RENT', 'REPLY', 'REPORT', 'REPORTER', 'REPUBLICAN', 'REQUEST', 'REQUIRE', 'RESEARCH', 'RESIDENCE/ADDRESS', 'RESONANCE', 'RESPONSIBILITY', 'RESTAURANT', 'RESULT', 'RESUME', 'RIBS', 'RICK-PERRY', 'RIDE', 'RIGHT', 'RIGHT-HERE', 'RING', 'RISK', 'RIT', 'RIVER', 'ROAD', 'ROCHESTER', 'ROCK', 'RODNEY', 'ROLE', 'ROLL-ON-FLOOR-LAUGHING', 'ROLLERBLADE', 'ROOF', 'ROOM', 'ROOMMATE', 'ROPE', 'ROW/PADDLE', 'ROWDY', 'ROWING', 'RSD', 'RUBBER', 'RUIN', 'RULE', 'RUMBLE', 'RUN', 'RUN-MACHINE', 'RUN-OUT', 'RUNNING-BACK', 'S', 'SACK', 'SAD', 'SAFE', 'SALE', 'SALLY', 'SAME', 'SAME-LIST', 'SAME-OLD', 'SAME-TIME', 'SANCTUARY', 'SARAH-JESSICA-PARKER', 'SARAH-PALIN', 'SARCASM', 'SAT', 'SATISFIED', 'SAVE-MONEY', 'SAY', 'SB', 'SCARE', 'SCHEDULE', 'SCHOOL', 'SCISSOR', 'SCL', 'SCOUT', 'SCRAPE', 'SCRATCH', 'SCREAM', 'SCREEN/FILTER', 'SD', 'SEAFOOD', 'SEARCH-FOR', 'SEASON', 'SEASONS', 'SEATTLE', 'SECOND', 'SECOND-IN-LIST', 'SEE', 'SEE-SEE', 'SEEM', 'SELECT', 'SELF', 'SELL', 'SEMESTER', 'SEND', 'SEND/MAIL', 'SENSE', 'SENSES', 'SENSORY', 'SENTENCE', 'SEPARATE', 'SEPT', 'SERIOUS', 'SERVICE', 'SET-ASIDE', 'SET-UP', 'SEVEN', 'SEVEN-THIRTY', 'SEW', 'SEWER', 'SF', 'SHAKE', 'SHAMPOO', 'SHARP', 'SHEEP', 'SHEET-CAKE', 'SHH', 'SHIRT', 'SHOCK', 'SHOE', 'SHOOT', 'SHORT', 'SHORT-HEIGHT', 'SHORTS', 'SHOULD', 'SHOW', 'SHOWER', 'SHUT', 'SIBERIAN', 'SICK', 'SICK-OF', 'SICK/SILLY', 'SIDE', 'SIGH', 'SIGN', 'SILBER', 'SILK', 'SILLY', 'SIMPLE', 'SIREN', 'SISTER', 'SIT', 'SITES', 'SITUATION', 'SIX', 'SIX-DAY', 'SIXTY', 'SIZE', 'SKI', 'SKILL', 'SLEEP', 'SLICE', 'SLOW', 'SMALL', 'SMASHED', 'SMELL', 'SMILE', 'SMIRK', 'SMOKE', 'SNEAK', 'SNOB', 'SNOW', 'SO', 'SO-SO', 'SOCIAL', 'SOCIAL-WORK', 'SOCIAL/INTERACT', 'SOCIALIZE', 'SOME', 'SOMETHING/ONE', 'SOMETIMES', 'SON', 'SOON', 'SORRY', 'SOUND', 'SOUP', 'SOUTH', 'SPA', 'SPARE', 'SPECIAL/EXCEPT', 'SPECIALIZATION', 'SPECIALTY', 'SPEECH', 'SPEECH/LECTURE', 'SPEECH/ORAL', 'SPEED', 'SPELL', 'SPEND', 'SPIN', 'SPINACH', 'SPIT', 'SPORT', 'SPRAIN', 'SPREAD', 'SPRING', 'SS', 'STADIUM', 'STAFF', 'STAMP', 'STAND', 'STAND-UP', 'STAR', 'START', 'STATE', 'STATION', 'STAY', 'STAY-AWAKE', 'STAY-AWAKE-ALL-NIGHT', 'STEAK', 'STEAL', 'STICK', 'STICK-ON-SURFACE', 'STICK-ON-THROAT', 'STILL', 'STITCH', 'STOMACH', 'STOOL', 'STOP', 'STORE', 'STORM', 'STORY', 'STRANGE', 'STRANGER', 'STRICT', 'STRING', 'STRIPE', 'STRIPES', 'STRONG', 'STRUGGLE', 'STUCK', 'STUDENT', 'STUDY', 'STYROFOAM', 'SUBLIMINAL-INFLUENCE', 'SUBTRACT', 'SUCCEED', 'SUE', 'SUFFER', 'SUGGEST', 'SUMMER', 'SUMMON', 'SUN', 'SUNBATHE', 'SUNNY', 'SUNRISE', 'SUNSCREEN', 'SUNSET', 'SUNSHINE', 'SUPERIOR', 'SUPPORT', 'SUPPOSE', 'SURF-INTERNET', 'SURFACE', 'SURGEON', 'SURPASS', 'SURPRISE', 'SUSHI', 'SUSPECT', 'SWASHBUCKLING', 'SWEETHEART', 'SWIM', 'SWIRLING', 'SWITCH', 'SYNTAX', 'SYSTEM', 'T', 'TABLE', 'TABOO', 'TACTILE', 'TAG', 'TAKE', 'TAKE-BREAK', 'TAKE-OFF', 'TAKE-OUT', 'TAKE-UP', 'TALK', 'TAN', 'TANK-TOP', 'TAPE-RECORDING', 'TASKS', 'TASTE', 'TD', 'TE', 'TEA', 'TEACH', 'TEACHER', 'TEAM', 'TEASE', 'TELL', 'TEMPT', 'TEN', 'TEND', 'TENN', 'TENSE', 'TEST', 'TESTIMONIES', 'TEXAS', 'TEXTING', 'THAN', 'THANK-YOU', 'THAT', 'THEN', 'THEREFORE', 'THICK', 'THING', 'THINK', 'THINK-OVER', 'THIRD', 'THIRD-IN-LIST', 'THIS', 'THOSE-TWO', 'THOUSAND', 'THREE', 'THREE-DAY', 'THREE-HOUR', \"THRILL/WHAT'S-UP\", 'THROUGH', 'THROW', 'THUMBS-UP/GOOD', 'THURSDAY', 'TIE', 'TIGER', 'TIME', 'TIME-FOUR', 'TIME-PERIOD', 'TIME-TWO', 'TIRE', 'TIRED', 'TJ', 'TO', 'TO/UNTIL', 'TODAY', 'TOGETHER', 'TOGETHER/GO-STEADY', 'TOILET', 'TOMORROW', 'TONY', 'TOO', 'TOOTH/GLASS', 'TOTAL', 'TOUCHDOWN', 'TOUGH', 'TOY', 'TRACE-PATH', 'TRACK-IX', 'TRACK-MIDDLE', 'TRACK-PINKY', 'TRACK-RING', 'TRACK-THUMB', 'TRADITION', 'TRAIN', 'TRANSFER', 'TRAY', 'TREAT', 'TREE', 'TRIP', 'TROUBLE', 'TRUCK', 'TRUE-BUSINESS', 'TRUNK', 'TRUST', 'TRY', 'TUBING', 'TURN', 'TURN-OFF', 'TV', 'TWELVE', 'TWENTY', 'TWENTY-FIVE', 'TWICE', 'TWO', 'TYPE', 'TYRANNY', 'U-L', 'UB', 'UE', 'UMBRELLA', 'UN', 'UNCLE', 'UNDER', 'UNDERSTAND', 'UNIVERSITY', 'UNLESS', 'UNTIL', 'UP', 'UP-TO-NOW', 'UPSET', 'URINE', 'US', 'USE', 'USE-SIGN-LANGUAGE', 'UTAH', 'V', 'VACATION', 'VALUE', 'VARIOUS', 'VARY', 'VEGETABLE', 'VENTRILOQUISM', 'VERY', 'VERY-FAST', 'VIBRATE', 'VIDEO-GAME', 'VIDEO-PHONE', 'VIDEOTAPE', 'VINCE', 'VISION', 'VISIT', 'VISUALIZE', 'VOCAL', 'VOICE', 'VOICE-RANGE', 'VOLUNTEER/SHIRT', 'VOMIT', 'VOMIT/HATE', 'VOTE', 'VP', 'VT', 'W', 'WAIT', 'WAITRESS', 'WAIVE', 'WAKE-UP', 'WALK', 'WALLET', 'WANT', 'WARM', 'WARN', 'WAS', 'WASH', 'WASTE', 'WATCH', 'WATCH-TV', 'WATER', 'WAVE-HELLO', 'WAVES', 'WAY', 'WEAR', 'WEATHER', 'WEDDING', 'WEEKEND', 'WELCOME', 'WET', 'WHAT', \"WHAT'S-UP\", 'WHEEL', 'WHEN', 'WHERE', 'WHEW/RELIEVED', 'WHICH', 'WHIP', 'WHITE', 'WHO', 'WHOLE', 'WHY', 'WIDE', 'WIDE-RECEIVER', 'WIFE', 'WIN', 'WINDOW', 'WINNER', 'WINNING', 'WISH', 'WITH', 'WOLF', 'WOMAN', 'WONDER', 'WONDERFUL', 'WOOD', 'WORD', 'WORK', 'WORK-OUT', 'WORK/BUSINESS', 'WORLD', 'WORRY', 'WORSE', 'WORTH', 'WOW', 'WOW/AWFUL', 'WRESTLE', 'WRITE', 'WRONG', 'WYOMING', 'X', 'XRAY', 'Y', 'YEAR', 'YEAR-LONG', 'YES', 'YESTERDAY', 'YOUNG', 'ZOMBIE', 'ZONE', 'ZOOM', '^', 'a', 'b', 'c', 'd', 'e', 'f', 'fs-', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v']\n",
      "num_eng_tokens 3092\n",
      "num_asl_tokens 1810\n"
     ]
    }
   ],
   "source": [
    "# generate\n",
    "    # 1) list of eng-asl sentence pairs\n",
    "    # 2) set of unique english vocab\n",
    "    # 3) set of unique asl vocab\n",
    "\n",
    "text_pairs = []\n",
    "eng_tokens = set()\n",
    "asl_tokens = set()\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "for line in lines:\n",
    "    pair = []\n",
    "    eng_text, asl_text = line.split(\"\\t\")\n",
    "    glosses = asl_text.split()\n",
    "    revised_glosses = [isolate_cl(gloss) for gloss in glosses]\n",
    "    asl_text = \" \".join(revised_glosses)\n",
    "    pair.append(eng_text.lower())\n",
    "    pair.append(asl_text)\n",
    "    text_pairs.append(pair)\n",
    "\n",
    "for pair in text_pairs:\n",
    "    sent_tokens = custom_eng_tokenize(pair[0])\n",
    "    for token in sent_tokens:\n",
    "        if token not in eng_tokens:\n",
    "            eng_tokens.add(token)\n",
    "            \n",
    "for pair in text_pairs:\n",
    "    sent_tokens = custom_asl_tokenize(pair[1])\n",
    "    for token in sent_tokens:\n",
    "        if token not in asl_tokens:\n",
    "            asl_tokens.add(token)\n",
    "\n",
    "eng_tokens = sorted(list(eng_tokens))\n",
    "asl_tokens = sorted(list(asl_tokens))\n",
    "\n",
    "print(\"eng_tokens:\", eng_tokens)\n",
    "print(\"asl_tokens\", asl_tokens)\n",
    "num_encoder_tokens = len(eng_tokens)\n",
    "num_decoder_tokens = len(asl_tokens)\n",
    "print(\"num_eng_tokens\", num_encoder_tokens)\n",
    "print(\"num_asl_tokens\", num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b587712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['really, all the way through nebraska...', 'REALLY THROUGH fs-NEB']\n",
      "['john wants to sell his car in the future.', 'fs-JOHN WANT SELL CAR FUTURE']\n",
      "['friends go to the beach to sunbathe because they are pale.', 'FRIEND GROUP/TOGETHER-pl fs-BEACH SUNBATHE DCL SUNBATHE (25)WHY IX fs-PALE']\n",
      "['mother walked to the store.', 'IX MOTHER IX SCL GO-OUT SELL']\n",
      "['if the president is elected again, my father will be upset.', 'IF PRESIDENT VOTE AGAIN POSS FATHER fs-UPSET FUTURE']\n"
     ]
    }
   ],
   "source": [
    "# glimpse pairs\n",
    "\n",
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c010cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3389 total pairs\n",
      "2373 training pairs\n",
      "508 validation pairs\n",
      "508 test pairs\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fba5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
    "    word_piece_ds = tf_data.Dataset.from_tensor_slices(text_samples)\n",
    "    vocab = keras_hub.tokenizers.compute_word_piece_vocabulary(\n",
    "        word_piece_ds.batch(500).prefetch(2),\n",
    "        vocabulary_size=vocab_size,\n",
    "        reserved_tokens=reserved_tokens,\n",
    "    )\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5335f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:16:29.994443: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-07-16 13:16:29.995384: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-07-16 13:16:29.996972: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752686190.003917 11484742 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1752686190.007227 11484742 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-07-16 13:16:30.826088: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-16 13:16:33.626015: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '[UNK]', '[START]', '[END]', '!', '\"', '$', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '“', '”', '…', 'the', 'to', 'and', '##s', 'it', 'is', 'he', 'my', 'that', 'was', 'you', 'in', 'john', '##ing', 'of', 'if', 'will', '##ed', 'for', 'have', 'when', 'did', 'they', 'car', '##d', 'there', 'at', 'on', 'because', 'who', 'we', '##y', 'no', 'but', 'out', 'friend', 'book', 'deaf', 'not', 'with', '##t', 'go', 'are', 'be', 'she', 'his', 'what', 'buy', '##n', 'like', 'mother', 'mary', '##e', '##er', 'people', 'up', 'so', 'do', 'me', '##a', 'had', 'know', 'teacher', 'as', 'friends', 'house', 'has', 'really', 'would', 'said', '##ly', 'can', 'person', 'don', '##k', 'all', 'going', 'her', 'went', 'father', '##r', 'him', 'didn', 'how', 'one', 'then', 'many', '##l', 'good', 'their', 'time', '##m', 'an', 'or', 'read', 'voice', '##al', '##es', 'about', 'down', 'were', 'work', 'does', 'now', 'where', 'over', 'from', 'some', '##h', 'just', 'why', '##all', 'night', '##et', 'bob', 'home', '##g', 'back', 'reading', '##ation', 'doesn', 'want', 'give', 'school', 'them', '##ies', '##ry', 'here', 'should', 'student', 'two', '##ow', 'hearing', 'party', 'see', '##ate', 'arrived', 'boston', 'looked', 'make', 'speech', 'books', 'likes', 'yesterday', '##or', 'loves', 'man', 'movie', '##ch', 'got', 'last', 'parents', 'sure', '##en', '##it', 'bought', 'get', 'mom', 'your', '##an', '##0', '##ted', 'different', 'gave', 'thought', 'chocolate', 'still', '##ce', '##ning', '##ter', 'by', 'driving', 'fine', 'new', 'off', '##ay', '##ue', 'cream', 'late', 'sister', 'this', 'won', '##ar', '##in', '##ity', 'lot', '##ion', '##ive', 'cheese', 'family', 'la', 'together', '##f', '##p', '##te', 'decided', '##ost', '##ve', 'cop', 'pineapple', 'started', 'told', '##o', 'something', 'wolf', '##ers', '##ide', '##ight', '##ting', '##ts', '##un', '##ure', 'after', 'big', 'more', 'must', 'right', 'students', 'wants', 'while', '##ge', '##le', '##ring', '##th', 'am', 'broken', 'group', 'into', 'isn', 'same', 'through', 'wasn', 'weather', '##ard', '##ee', '##ic', '##il', '##ire', '##se', '##self', '##ver', 'again', 'already', 'even', 'finish', 'homework', 'maybe', 'movies', 'need', 'play', 'range', 'tell', 'think', 'wow', '##st', 'around', 'arrive', 'bathroom', 'beach', 'could', 'drive', 'finished', 'love', 'next', 'rain', 'someone', 'store', 'very', '##ance', '##ary', '##ut', 'before', 'example', 'game', 'making', 'pizza', 'pulled', 'thing', 'tomorrow', 'us', '##ad', '##ally', '##c', '##nt', 'another', 'day', 'drove', 'high', 'll', 'move', 'noises', 'other', 'saw', 'sick', 'take', 'talking', 'things', 'three', 'video', 'well', 'which', '##ange', '##ant', '##at', '##ations', '##ct', '##day', '##ey', '##ine', '##ld', '##ually', 'asked', 'bad', 'been', 'broke', 'class', 'eat', 'experience', 'found', 'goes', 'hand', 'long', 'means', 'money', 'only', 'pigs', 'stay', 'use', 'walked', '##age', '##ice', '##ited', '##ose', '##ough', '##wn', 'break', 'each', 'hear', 'hit', 'outside', 'water', 'way', 'year', 'years', '##able', '##dy', '##ia', '##ious', '##king', '##ows', '##room', '##w', 'buying', 'cancelled', 'dog', 'never', 'noise', 'oh', 'rains', 'sat', 'start', 'test', 'took', '##ack', '##ast', '##her', '##ind', '##ise', '##ke', '##ms', '##on', '##owing', '##us', 'better', 'dana', 'find', 'food', 'grass', 'made', 'often', 'pay', 'playing', 'raining', 'ready', 'tend', 'those', 've', '##aid', '##cept', '##ction', '##der', '##ding', '##eam', '##ell', '##ent', '##fer', '##i', '##ick', '##id', '##ite', '##lt', '##ome', '##ps', '##und', '##ven', 'any', 'beautiful', 'care', 'dinner', 'feel', 'giving', 'kitchen', 'loud', 're', 'starts', 'than', 'today', 'too', 'walk', 'wanted', 'watch', 'woman', 'wouldn', 'yet', '##ake', '##and', '##ape', '##cted', '##ft', '##go', '##ible', '##ize', '##led', '##ment', '##mit', '##ood', '##ore', '##ple', '##ried', '##rs', '##uck', '##ute', 'across', 'bike', 'born', 'boy', 'cars', 'control', 'deer', 'every', 'fireworks', 'fishing', 'football', 'hospital', 'hot', 'kind', 'president', 'put', 'say', 'soon', '##ared', '##arly', '##as', '##ful', '##ir', '##ived', '##lated', '##nd', '##ned', '##ng', '##oat', '##op', '##ope', '##ort', '##ped', '##ping', '##rry', '##ses', '##ss', '##thing', '##tle', '##tory', '##ves', '##ycle', 'ahead', 'aunt', 'away', 'baby', 'bill', 'came', 'clean', 'enjoy', 'funny', 'games', 'join', 'list', 'look', 'office', 'old', 'rent', 'road', 'san', 'seen', 'tends', 'trip', 'wife', 'wrong', 'yes', '##ain', '##aking', '##ale', '##ark', '##arm', '##ashed', '##ass', '##ated', '##ating', '##aving', '##band', '##ble', '##bly', '##ches', '##eat', '##eep', '##end', '##ep', '##fe', '##hing', '##ics', '##ie', '##ied', '##ince', '##is', '##ks', '##li', '##ls', '##mber', '##mming', '##ne', '##ock', '##ocked', '##oming', '##one', '##ord', '##ox', '##ress', '##rew', '##set', '##stairs', '##urn', '##urse', 'area', 'arrives', 'camping', 'character', 'child', 'couldn', 'cultural', 'diego', 'directions', 'door', 'everyone', 'happens', 'identity', 'job', 'laugh', 'left', 'letter', 'looking', 'makes', 'morning', 'much', 'name', 'our', 'phone', 'place', 'puppies', 'six', 'week', '##!', '##\"', '##$', \"##'\", '##(', '##)', '##*', '##,', '##-', '##.', '##/', '##1', '##2', '##3', '##4', '##5', '##6', '##7', '##8', '##9', '##:', '##;', '##?', '##`', '##b', '##j', '##q', '##u', '##v', '##x', '##z', '##—', '##“', '##”', '##…']\n",
      "['[PAD]', '[UNK]', '[START]', '[END]', '#', \"'\", '(', ')', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'y', 'IX', 'fs', 'NOT', 'POSS', 'REALLY', 'JOHN', 'DCL', 'MOTHER', 'FRIEND', 'SCL', 'GO', 'FUTURE', 'OUT', 'CAR', 'WHY', 'IN', 'LOOK', 'FINISH', 'BOOK', 'BUY', 'IF', 'ONE', 'HAVE', '##Y', 'WORK', 'THAT', '##E', 'WHO', 'FATHER', 'UP', 'MUST', 'FOR', 'NOW', '25', 'TO', 'READ', 'ICL', 'NIGHT', 'KNOW', 'AGENT', 'BCL', 'MARY', 'LIKE', 'DO', '##S', 'DEAF', 'SEE', 'WANT', 'SAME', 'PAST', '##D', 'WHEN', 'VOICE', '##T', 'ARRIVE', 'WITH', 'BUT', 'FIND', 'TEACH', 'MAKE', 'WOW', 'QM', 'DRIVE', 'SO', 'TOGETHER', '##A', 'BUOY', 'MANY', 'NO', 'NONE', 'PEOPLE', 'STUDENT', 'LIST', 'NOTHING', 'BREAK', 'CAN', 'ON', 'MOVIE', '##ER', '##ING', 'GROUP', 'HEAR', 'HOUSE', 'FINE', '##M', 'GOOD', 'HOME', 'RAIN', 'TIME', 'WHERE', 'EAT', 'ALL', 'HOW', 'TAKE', 'NOISE', '##AL', 'AND', 'PLAY', 'THINK', 'BOB', '##ATE', 'TEACHER', 'MEAN', 'SAY', 'SOMETHING', 'TEND', '##N', '##OR', '##P', 'OF', 'UNTIL', 'THANK', 'YOU', '1p', 'OVER', '##O', 'PARTY', '##L', 'RANGE', '##R', 'BPCL', 'DOWN', 'NEG', 'TALK', '##OW', 'ABOUT', 'CREAM', 'SHOULD', 'TELL', 'YESTERDAY', '##F', 'CHEESE', 'CLASS', 'PAY', '##INE', '##RY', 'HERE', 'MORE', 'SELF', '##ALL', '##ED', '##K', 'DEPART', 'DIFFERENT', 'FROM', 'PROCEED', 'STILL', '##CH', 'MAYBE', 'OH', 'TWO', '##AN', '##H', 'BOSTON', 'LOVE', 'MAN', 'SCHOOL', '##IT', 'CHOCOLATE', 'GET', 'NEW', '1h', 'CANNOT', 'OTHER', 'START', '##AR', '##TER', 'FIST', 'IT', 'KISS', 'LIVE', 'YEAR', '##EN', 'DECIDE', 'EXPERIENCE', 'GIFT', 'HEARING', 'NICE', 'PLACE', 'SICK', 'SISTER', 'STAY', 'BOX', 'CLEAN', 'ENTER', 'FEEL', 'LATE', 'RECENT', 'SPEECH', 'THING', 'nd', '##ION', 'BUSINESS', 'EVERY', 'LONG', 'PINEAPPLE', '##AT', '##C', '##TE', 'AREA', 'GAME', 'USE', '##ACK', '##CE', '##ICE', '##ST', '##UT', 'BEACH', 'FAMILY', 'LA', 'OR', 'REFUSE', 'ROOM', 'THREE', 'YET', '##IRE', '##ITY', '##UN', 'AWFUL', 'CULTURE', 'DOG', 'KIND', 'MOVE', 'PERSON', 'SCREAM', 'SOME', 'TOMORROW', '##B', '##G', 'BELONG', 'BLUE', 'COP', 'DAY', 'GROW', 'INFORM', 'LCL', 'OK', 'ORDER', 'SELL', 'TRIP', '##AGE', '##EE', '##IE', '##OOD', '##TY', '##US', 'EACH', 'ENJOY', 'FAVORITE', 'HAPPEN', 'NAME', 'PREFER', 'SHOW', 'SIX', 'continuative', '##ARY', '##DAY', '##ICK', '##IGHT', '##LE', '##OP', '##UE', 'ANY', 'CHAT', 'NEXT', 'SNOW', 'WEATHER', 'arc', '##AD', '##ANCE', '##I', '##ILL', '##ME', '##PLE', '##RESS', '##TH', 'BAD', 'BEFORE', 'BORN', 'BOY', 'CANCEL', 'CRITICIZE', 'FIRST', 'LAUGH', 'NEVER', 'PHONE', 'STUDY', 'VOMIT', '##AKE', '##ARE', '##ATCH', '##AVE', '##ES', '##IVE', '##OSE', '##OURSE', '##SE', '##URE', 'BICYCLE', 'BIG', 'CONTROL', 'HATE', 'HIT', 'MANAGE', 'PIZZA', 'READY', 'SEND', 'TOILET', 'VEGETABLE', '##ALE', '##ASS', '##ECT', '##GE', '##IDE', '##ON', '##USE', '##X', 'AGAIN', 'AWAY', 'DIRECT', 'GIV', 'HOMEWORK', 'HOPE', 'HOSPITAL', 'JOIN', 'MAIL', 'SPEND', 'WIN', 'flat', '##ACT', '##APE', '##CLE', '##REE', '##t', 'EXPLAIN', 'GRASS', 'HORSE', 'INTERNET', 'INTERPRET', 'KID', 'LOT', 'MORNING', 'SOON', 'STORY', 'WATER', 'WHAT', 'WHICH', 'WIFE', 'WRITE', '##BAND', '##DER', '##IA', '##IOUS', '##LY', '##SET', '##UTE', 'AFTER', 'BETTER', 'BORE', 'COMMUNICATE', 'CORRECT', 'DANA', 'FUNNY', 'GIRL', 'GRUNT', 'HARD', 'KITCHEN', 'OFTEN', 'OLD', 'PAPER', 'PCL', 'TEST', 'TOPIC', 'TRUE', 'VISUALIZE', 'WOMAN', 'crvd', '##0', '##ANT', '##DING', '##IN', '##LOW', '##MB', '##NER', '##OAT', '##OUGH', '##PT', '##SS', '##ZE', 'ACT', 'ASK', 'BERRY', 'CARE', 'EARLY', 'FACE', 'FIRE', 'FLOWER', 'HOT', 'HS', 'LEARN', 'MEET', 'PIG', 'PRESIDENT', 'QUOTE', 'SET', 'SHIRT', 'SURPRISE', 'THEN', 'THROUGH', 'UNDERSTAND', 'VERY', 'VIDEO', 'WAIT', 'WHILE', 'pl', '##AID', '##ALD', '##ANGE', '##CEPT', '##ISH', '##ITE', '##MIT', '##ONE', '##OTHER', '##RRY', '##W', '##WAY', 'ALSO', 'ALWAYS', 'BEAUTIFUL', 'BECAUSE', 'CAMP', 'COMMUTE', 'DISCUSS', 'DURING', 'FAST', 'FORGET', 'FORMERLY', 'GRAB', 'INVOLVE', 'LETTER', 'LOUD', 'MONEY', 'PIE', 'SECOND', 'WRONG', 'YES', '##AND', '##EAR', '##EED', '##EL', '##ET', '##EY', '##IC', '##IM', '##IS', '##ISS', '##OCK', '##UCK', 'ACCEPT', 'AGE', 'AGO', 'AUNT', 'BIT', 'CHANCE', 'END', 'EVEN', 'FALL', 'FISHING', 'IDENTIFY', 'INCLUDE', 'LISTEN', 'LITTLE', 'ONLY', 'REASON', 'RENT', 'SEVEN', 'SOCIAL', 'STRANGE', 'VACATION', 'WARN', 'WORD', '##AIR', '##ALLY', '##ATION', '##BLE', '##EARCH', '##GH', '##IL', '##INT', '##KS', '##LD', '##LI', '##ORT', '##RACK', '##ROUND', '##RUNK', '##TEEN', '##UNITY', '##VER', '2p', 'ABOVE', 'ACCIDENT', 'ACTION', 'AMONG', 'BABY', 'BECOME', 'BRING', 'CHARACTER', 'CLOSE', 'CLOTHES', 'COLD', 'COURT', 'CRASH', 'DRESS', 'FARM', 'FOOTBALL', 'FOUR', 'HALF', 'LAST', 'MIND', 'MOST', 'ORAL', 'PARK', 'RUMBLE', 'SD', 'SIGN', 'SITUATION', 'SLEEP', 'THIRD', 'WEEK', '###', \"##'\", '##(', '##)', '##+', '##-', '##.', '##/', '##1', '##2', '##3', '##4', '##5', '##6', '##7', '##8', '##9', '##>', '##J', '##Q', '##U', '##V', '##Z', '##^', '##_', '##a', '##b', '##c', '##d', '##e', '##f', '##h', '##i', '##j', '##k', '##l', '##m', '##n', '##o', '##p', '##r', '##s', '##u', '##v', '##y']\n"
     ]
    }
   ],
   "source": [
    "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "\n",
    "eng_samples = [text_pair[0] for text_pair in train_pairs]\n",
    "trained_eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE, reserved_tokens)\n",
    "\n",
    "asl_samples = [text_pair[1] for text_pair in train_pairs]\n",
    "trained_asl_vocab = train_word_piece(asl_samples, ASL_VOCAB_SIZE, reserved_tokens)\n",
    "\n",
    "print(trained_eng_vocab)\n",
    "print(trained_asl_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0e3764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Tokens:  ['go', 'are', 'be', 'she', 'his', 'what', 'buy', '##n', 'like', 'mother']\n",
      "ASL Tokens:  ['FATHER', 'UP', 'MUST', 'FOR', 'NOW', '25', 'TO', 'READ', 'ICL', 'NIGHT']\n"
     ]
    }
   ],
   "source": [
    "print(\"English Tokens: \", trained_eng_vocab[100:110])\n",
    "print(\"ASL Tokens: \", trained_asl_vocab[100:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9895e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = keras_hub.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=trained_eng_vocab, lowercase=False\n",
    ")\n",
    "asl_tokenizer = keras_hub.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=trained_asl_vocab, lowercase=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb29eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence:  the teacher didn't make the reading required. it's uncertain whether or not john will read the book now.\n",
      "Tokens:  tf.Tensor(\n",
      "[ 59 121 141   7  48 198  59 177 472 664 665 296  83  13  63   7  47  49\n",
      " 107 226 139  99 567  51 167 172 424 152  97  71  75 153  59  95 162  13], shape=(36,), dtype=int32)\n",
      "Recovered text after detokenizing:  the teacher didn ' t make the reading required . it ' s uncertain whether or not john will read the book now .\n",
      "\n",
      "ASL sentence:  TEACH+AGENT TEACH+AGENT NOT REQUIRE BOOK READ DROP IX fs-JOHN FUTURE READ BOOK\n",
      "Tokens:  tf.Tensor(\n",
      "[130   8 111 130   8 111  74  40  98 622 623 287  90 107  26 191 332  72\n",
      "  73   9  77  83 107  90], shape=(24,), dtype=int32)\n",
      "Recovered text after detokenizing:  TEACH + AGENT TEACH + AGENT NOT REQUIRE BOOK READ DROP IX fs - JOHN FUTURE READ BOOK\n"
     ]
    }
   ],
   "source": [
    "eng_input_ex = text_pairs[0][0]\n",
    "eng_tokens_ex = eng_tokenizer.tokenize(eng_input_ex)\n",
    "print(\"English sentence: \", eng_input_ex)\n",
    "print(\"Tokens: \", eng_tokens_ex)\n",
    "print(\n",
    "    \"Recovered text after detokenizing: \",\n",
    "    eng_tokenizer.detokenize(eng_tokens_ex),\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "asl_input_ex = text_pairs[0][1]\n",
    "asl_tokens_ex = asl_tokenizer.tokenize(asl_input_ex)\n",
    "print(\"ASL sentence: \", asl_input_ex)\n",
    "print(\"Tokens: \", asl_tokens_ex)\n",
    "print(\n",
    "    \"Recovered text after detokenizing: \",\n",
    "    asl_tokenizer.detokenize(asl_tokens_ex),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3c4a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(eng, asl):\n",
    "    eng = eng_tokenizer(eng)\n",
    "    asl = asl_tokenizer(asl)\n",
    "\n",
    "    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n",
    "    eng_start_end_packer = keras_hub.layers.StartEndPacker(\n",
    "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n",
    "    )\n",
    "    eng = eng_start_end_packer(eng)\n",
    "\n",
    "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `asl` and pad it as well.\n",
    "    asl_start_end_packer = keras_hub.layers.StartEndPacker(\n",
    "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
    "        start_value=asl_tokenizer.token_to_id(\"[START]\"),\n",
    "        end_value=asl_tokenizer.token_to_id(\"[END]\"),\n",
    "        pad_value=asl_tokenizer.token_to_id(\"[PAD]\"),\n",
    "    )\n",
    "    asl = asl_start_end_packer(asl)\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\": asl[:, :-1],\n",
    "        },\n",
    "        asl[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, asl_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    asl_texts = list(asl_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, asl_texts))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "    return dataset.shuffle(1400).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a04a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (16, 150)\n",
      "inputs[\"decoder_inputs\"].shape: (16, 150)\n",
      "targets.shape: (16, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:16:36.457956: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebed136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n",
    "\n",
    "x = keras_hub.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=ENG_VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_outputs = keras_hub.layers.TransformerEncoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(inputs=x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
    "\n",
    "x = keras_hub.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=ASL_VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    ")(decoder_inputs)\n",
    "\n",
    "x = keras_hub.layers.TransformerDecoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = keras.layers.Dense(ASL_VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "decoder = keras.Model(\n",
    "    [\n",
    "        decoder_inputs,\n",
    "        encoded_seq_inputs,\n",
    "    ],\n",
    "    decoder_outputs,\n",
    ")\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    decoder_outputs,\n",
    "    name=\"transformer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "092c923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">415,488</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ token_and_positi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">749,974</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1814</span>)             │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m415,488\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m198,272\u001b[0m │ token_and_positi… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │    \u001b[38;5;34m749,974\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1814\u001b[0m)             │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,734</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,363,734\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,734</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,734\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 13:16:38.225538: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 156ms/step - accuracy: 0.8594 - loss: 1.6322 - val_accuracy: 0.9102 - val_loss: 0.5263\n",
      "Epoch 2/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 160ms/step - accuracy: 0.9082 - loss: 0.5348 - val_accuracy: 0.9129 - val_loss: 0.4736\n",
      "Epoch 3/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 180ms/step - accuracy: 0.9110 - loss: 0.4885 - val_accuracy: 0.9148 - val_loss: 0.4506\n",
      "Epoch 4/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 237ms/step - accuracy: 0.9121 - loss: 0.4674 - val_accuracy: 0.9154 - val_loss: 0.4378\n",
      "Epoch 5/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 212ms/step - accuracy: 0.9128 - loss: 0.4534 - val_accuracy: 0.9161 - val_loss: 0.4309\n",
      "Epoch 6/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 192ms/step - accuracy: 0.9135 - loss: 0.4430 - val_accuracy: 0.9164 - val_loss: 0.4240\n",
      "Epoch 7/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 244ms/step - accuracy: 0.9136 - loss: 0.4368 - val_accuracy: 0.9166 - val_loss: 0.4209\n",
      "Epoch 8/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 175ms/step - accuracy: 0.9142 - loss: 0.4298 - val_accuracy: 0.9170 - val_loss: 0.4177\n",
      "Epoch 9/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 167ms/step - accuracy: 0.9150 - loss: 0.4239 - val_accuracy: 0.9174 - val_loss: 0.4145\n",
      "Epoch 10/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 165ms/step - accuracy: 0.9152 - loss: 0.4214 - val_accuracy: 0.9173 - val_loss: 0.4127\n",
      "Epoch 11/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 169ms/step - accuracy: 0.9152 - loss: 0.4171 - val_accuracy: 0.9177 - val_loss: 0.4116\n",
      "Epoch 12/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 166ms/step - accuracy: 0.9155 - loss: 0.4136 - val_accuracy: 0.9177 - val_loss: 0.4117\n",
      "Epoch 13/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 183ms/step - accuracy: 0.9161 - loss: 0.4099 - val_accuracy: 0.9177 - val_loss: 0.4134\n",
      "Epoch 14/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 186ms/step - accuracy: 0.9163 - loss: 0.4081 - val_accuracy: 0.9181 - val_loss: 0.4090\n",
      "Epoch 15/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 173ms/step - accuracy: 0.9170 - loss: 0.4060 - val_accuracy: 0.9185 - val_loss: 0.4085\n",
      "Epoch 16/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 165ms/step - accuracy: 0.9172 - loss: 0.4027 - val_accuracy: 0.9188 - val_loss: 0.4068\n",
      "Epoch 17/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 181ms/step - accuracy: 0.9176 - loss: 0.3987 - val_accuracy: 0.9193 - val_loss: 0.4054\n",
      "Epoch 18/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 170ms/step - accuracy: 0.9183 - loss: 0.3965 - val_accuracy: 0.9198 - val_loss: 0.4012\n",
      "Epoch 19/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 171ms/step - accuracy: 0.9190 - loss: 0.3913 - val_accuracy: 0.9208 - val_loss: 0.3994\n",
      "Epoch 20/20\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 184ms/step - accuracy: 0.9200 - loss: 0.3873 - val_accuracy: 0.9216 - val_loss: 0.3958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3098bedd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad617331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752686745.973149 11484742 service.cc:152] XLA service 0x387911870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752686745.973548 11484742 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1752686746.327616 11484742 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "def decode_sequences(input_sentences):\n",
    "    with tf.device('/CPU:0'):\n",
    "        batch_size = 1\n",
    "\n",
    "        # Tokenize the encoder input.\n",
    "        encoder_input_tokens = ops.convert_to_tensor(eng_tokenizer(input_sentences))\n",
    "        if len(encoder_input_tokens[0]) < MAX_SEQUENCE_LENGTH:\n",
    "            pads = ops.full((1, MAX_SEQUENCE_LENGTH - len(encoder_input_tokens[0])), 0)\n",
    "            encoder_input_tokens = ops.concatenate(\n",
    "                [encoder_input_tokens, pads], 1\n",
    "            )\n",
    "\n",
    "        # Define a function that outputs the next token's probability given the\n",
    "        # input sequence.\n",
    "        def next(prompt, cache, index):\n",
    "            logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n",
    "            # Ignore hidden states for now; only needed for contrastive search.\n",
    "            hidden_states = None\n",
    "            return logits, hidden_states, cache\n",
    "\n",
    "        # Build a prompt of length 40 with a start token and padding tokens.\n",
    "        length = 40\n",
    "        start = ops.full((batch_size, 1), asl_tokenizer.token_to_id(\"[START]\"))\n",
    "        pad = ops.full((batch_size, length - 1), asl_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        prompt = ops.concatenate((start, pad), axis=-1)\n",
    "\n",
    "\n",
    "        generated_tokens = keras_hub.samplers.GreedySampler()(\n",
    "                next,\n",
    "                prompt,\n",
    "                stop_token_ids=[asl_tokenizer.token_to_id(\"[END]\")],\n",
    "                index=1,  # Start sampling after start token.\n",
    "            )\n",
    "        generated_sentences = asl_tokenizer.detokenize(generated_tokens)\n",
    "    return generated_sentences\n",
    "\n",
    "outputs = []\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for i in range(200):\n",
    "    output_pairs = []\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequences([input_sentence])\n",
    "    translated = translated[0]\n",
    "    translated = (\n",
    "        translated.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    output_pairs.append(input_sentence)\n",
    "    output_pairs.append(translated)\n",
    "    outputs.append(output_pairs)\n",
    "    \n",
    "df = pd.DataFrame(outputs, columns=[\"input sentence\", \"translation\"])\n",
    "df.to_csv(\"/Users/adrianajimenez/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/seq2seq_code/word_level/joined_outputs1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881ff7aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m test_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m reference_sentence \u001b[38;5;241m=\u001b[39m test_pair[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m translated_sentence[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m     translated_sentence\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[START]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[END]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     15\u001b[0m )\n",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m, in \u001b[0;36mdecode_sequences\u001b[0;34m(input_sentences)\u001b[0m\n\u001b[1;32m     24\u001b[0m     pad \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mfull((batch_size, length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), asl_tokenizer\u001b[38;5;241m.\u001b[39mtoken_to_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     25\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconcatenate((start, pad), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGreedySampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop_token_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43masl_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[END]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Start sampling after start token.\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     generated_sentences \u001b[38;5;241m=\u001b[39m asl_tokenizer\u001b[38;5;241m.\u001b[39mdetokenize(generated_tokens)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_sentences\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras_hub/src/samplers/sampler.py:120\u001b[0m, in \u001b[0;36mSampler.__call__\u001b[0;34m(self, next, prompt, cache, index, mask, stop_token_ids, hidden_states, model)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Return the next prompt, cache and incremented index.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (prompt, cache, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m prompt, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras_hub/src/samplers/sampler.py:201\u001b[0m, in \u001b[0;36mSampler.run_loop\u001b[0;34m(self, cond, body, model, loop_vars, maximum_iterations)\u001b[0m\n\u001b[1;32m    199\u001b[0m         ref_v\u001b[38;5;241m.\u001b[39massign(v)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loop_vars\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/core.py:575\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, maximum_iterations)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.while_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwhile_loop\u001b[39m(\n\u001b[1;32m    535\u001b[0m     cond,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m     maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    539\u001b[0m ):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"While loop implementation.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    10, 11\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:622\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, maximum_iterations)\u001b[0m\n\u001b[1;32m    619\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m body(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(outputs) \u001b[38;5;28;01mif\u001b[39;00m is_tuple \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[0;32m--> 622\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs \u001b[38;5;28;01mif\u001b[39;00m is_tuple \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:660\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    653\u001b[0m         _log_deprecation(\n\u001b[1;32m    654\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    655\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    659\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/while_loop.py:241\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m                   maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     53\u001b[0m                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python for-\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_invariants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m      \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m      \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreturn_same_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/while_loop.py:488\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m    485\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m    486\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m--> 488\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    490\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/while_loop.py:479\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m    476\u001b[0m     loop_vars \u001b[38;5;241m=\u001b[39m (counter, loop_vars)\n\u001b[1;32m    477\u001b[0m     cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (  \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         math_ops\u001b[38;5;241m.\u001b[39mlogical_and(i \u001b[38;5;241m<\u001b[39m maximum_iterations, orig_cond(\u001b[38;5;241m*\u001b[39mlv)))\n\u001b[0;32m--> 479\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m i, lv: (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[43morig_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    480\u001b[0m   try_to_pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executing_eagerly:\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:619\u001b[0m, in \u001b[0;36mwhile_loop.<locals>._body\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_body\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 619\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(outputs) \u001b[38;5;28;01mif\u001b[39;00m is_tuple \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras_hub/src/samplers/sampler.py:106\u001b[0m, in \u001b[0;36mSampler.__call__.<locals>.body\u001b[0;34m(prompt, cache, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbody\u001b[39m(prompt, cache, index):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# Compute the softmax distribution for the next token.\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     logits, _, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_probabilities(logits)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# Compute the next token.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m, in \u001b[0;36mdecode_sequences.<locals>.next\u001b[0;34m(prompt, cache, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnext\u001b[39m(prompt, cache, index):\n\u001b[0;32m---> 16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Ignore hidden states for now; only needed for contrastive search.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:183\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m             backend\u001b[38;5;241m.\u001b[39mset_keras_mask(x, mask)\n\u001b[0;32m--> 183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/function.py:177\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    175\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:648\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    643\u001b[0m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_context_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     ):\n\u001b[1;32m    646\u001b[0m         kwargs[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:183\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m             backend\u001b[38;5;241m.\u001b[39mset_keras_mask(x, mask)\n\u001b[0;32m--> 183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/function.py:177\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    175\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:648\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    643\u001b[0m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_context_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     ):\n\u001b[1;32m    646\u001b[0m         kwargs[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras_hub/src/layers/modeling/transformer_decoder.py:358\u001b[0m, in \u001b[0;36mTransformerDecoder.call\u001b[0;34m(self, decoder_sequence, encoder_sequence, decoder_padding_mask, decoder_attention_mask, encoder_padding_mask, encoder_attention_mask, self_attention_cache, self_attention_cache_update_index, cross_attention_cache, cross_attention_cache_update_index, use_causal_mask, training)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_first:\n\u001b[1;32m    357\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_attention_layer_norm(x)\n\u001b[0;32m--> 358\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_self_attention_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attention_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_update_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attention_cache_update_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_attention_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     x \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras_hub/src/layers/modeling/cached_multi_head_attention.py:80\u001b[0m, in \u001b[0;36mCachedMultiHeadAttention.call\u001b[0;34m(self, query, value, key, attention_mask, cache, cache_update_index, training)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     key \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 80\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# If cache is not `None`, we will use the cache to compute the final key\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# and value tensors. If `cache_update_index` is not None, we will first\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# update the cache before use. To do this, we first call the\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# `_key_dense` and `_value_dense` layers, and copy the outputs into the\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# cache at the specified index. `cache = None` handles the training\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# case, where we don't use the cache at all.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:936\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/operation.py:58\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     54\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m         call_fn,\n\u001b[1;32m     56\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/layers/core/einsum_dense.py:210\u001b[0m, in \u001b[0;36mEinsumDense.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         x \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39madd(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/ops/numpy.py:2855\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(subscripts, *operands)\u001b[0m\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(operands):\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Einsum(subscripts)\u001b[38;5;241m.\u001b[39msymbolic_call(\u001b[38;5;241m*\u001b[39moperands)\n\u001b[0;32m-> 2855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py:435\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(subscripts, *operands, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         compute_dtype \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m    432\u001b[0m     operands \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mcast(x, compute_dtype), operands\n\u001b[1;32m    434\u001b[0m     )\n\u001b[0;32m--> 435\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43muse_custom_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# TODO: tf.einsum doesn't support integer dtype with gpu\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m compute_dtype:\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py:325\u001b[0m, in \u001b[0;36meinsum.<locals>.use_custom_ops\u001b[0;34m(subscripts, output_type, *operands)\u001b[0m\n\u001b[1;32m    323\u001b[0m c2, d2, e2 \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    324\u001b[0m b, c, d, e \u001b[38;5;241m=\u001b[39m b1, c1 \u001b[38;5;129;01mor\u001b[39;00m c2, d2, e2\n\u001b[0;32m--> 325\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m result \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(x, y, output_type\u001b[38;5;241m=\u001b[39moutput_type)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(result, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, b, d, e])\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:199\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanip.reshape\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreshape\u001b[39m(tensor, shape, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m   shape_util\u001b[38;5;241m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:8795\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8793\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   8794\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 8795\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreshape_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8796\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m   8798\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:8820\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8818\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [tensor, shape]\n\u001b[1;32m   8819\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tshape)\n\u001b[0;32m-> 8820\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8821\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m   8823\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m   8824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m~/Desktop/Downloads/REUAICT/Real-Code/2025-ASL-data/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rouge_1 = keras_hub.metrics.RougeN(order=1)\n",
    "rouge_2 = keras_hub.metrics.RougeN(order=2)\n",
    "\n",
    "for test_pair in test_pairs:\n",
    "    input_sentence = test_pair[0]\n",
    "    reference_sentence = test_pair[1]\n",
    "\n",
    "    translated_sentence = decode_sequences([input_sentence])\n",
    "    translated_sentence = translated_sentence[0]\n",
    "    translated_sentence = (\n",
    "        translated_sentence.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    rouge_1(reference_sentence, translated_sentence)\n",
    "    rouge_2(reference_sentence, translated_sentence)\n",
    "\n",
    "print(\"ROUGE-1 Score: \", rouge_1.result())\n",
    "print(\"ROUGE-2 Score: \", rouge_2.result())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
